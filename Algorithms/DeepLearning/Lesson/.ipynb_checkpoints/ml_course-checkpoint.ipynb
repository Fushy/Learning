{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddc00fc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Sources <a class=\"tocSkip\">\n",
    "+ Deep Learning with Python - Fran√ßois Chollet\n",
    "    + https://www.manning.com/books/deep-learning-with-python\n",
    "    + https://www.manning.com/books/deep-learning-with-python-second-edition\n",
    "    + https://github.com/fchollet/deep-learning-with-python-notebooks \n",
    "+ https://keras.io/\n",
    "+ ChatGPT-4 May 24 Version & July 20 Version\n",
    "+ https://brilliant.org/wiki\n",
    "+ https://en.wikipedia.org/wiki/Outline_of_artificial_intelligence\n",
    "\n",
    "All definitions are provided in the context of artificial intelligence.<br>All images are sourced\n",
    "    \n",
    "##### TODO<a class=\"tocSkip\">\n",
    "+ images\n",
    "+ ram allocation\n",
    "+ Model tuning\n",
    "+ semi learning\n",
    "+ https://mxnet.apache.org/versions/1.9.1/api/faq/float16\n",
    "+ https://paperswithcode.com/sota/image-classification-on-imagenet?metric=Top%205%20Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79239c69",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Fields\" data-toc-modified-id=\"Fields-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Fields</a></span><ul class=\"toc-item\"><li><span><a href=\"#Artificial-Intelligence-(AI)\" data-toc-modified-id=\"Artificial-Intelligence-(AI)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Artificial Intelligence (AI)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Artificial-General-Intelligence-(AGI)\" data-toc-modified-id=\"Artificial-General-Intelligence-(AGI)-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Artificial General Intelligence (AGI)</a></span></li><li><span><a href=\"#Singularity\" data-toc-modified-id=\"Singularity-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Singularity</a></span></li><li><span><a href=\"#Alignment\" data-toc-modified-id=\"Alignment-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Alignment</a></span></li></ul></li><li><span><a href=\"#Machine-learning-(ML)\" data-toc-modified-id=\"Machine-learning-(ML)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Machine learning (ML)</a></span></li><li><span><a href=\"#Artificial-Neural-Networks-(ANNs)\" data-toc-modified-id=\"Artificial-Neural-Networks-(ANNs)-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Artificial Neural Networks (ANNs)</a></span></li><li><span><a href=\"#Deep-Learning-(DL)\" data-toc-modified-id=\"Deep-Learning-(DL)-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Deep Learning (DL)</a></span></li><li><span><a href=\"#Shallow-learning\" data-toc-modified-id=\"Shallow-learning-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Shallow learning</a></span></li><li><span><a href=\"#Natural-Language-Processing-(NLP)\" data-toc-modified-id=\"Natural-Language-Processing-(NLP)-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Natural Language Processing (NLP)</a></span></li></ul></li><li><span><a href=\"#Learning-algorithms\" data-toc-modified-id=\"Learning-algorithms-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Learning algorithms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Supervised-(Deep)-Learning\" data-toc-modified-id=\"Supervised-(Deep)-Learning-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Supervised (Deep) Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classification-problems\" data-toc-modified-id=\"Classification-problems-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Classification problems</a></span></li><li><span><a href=\"#Regression-problems\" data-toc-modified-id=\"Regression-problems-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Regression problems</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lineare-regression\" data-toc-modified-id=\"Lineare-regression-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>Lineare regression</a></span></li></ul></li></ul></li><li><span><a href=\"#Unsupervised-(Deep)-Learning\" data-toc-modified-id=\"Unsupervised-(Deep)-Learning-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Unsupervised (Deep) Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Clustering</a></span></li><li><span><a href=\"#Dimensionality-Reduction\" data-toc-modified-id=\"Dimensionality-Reduction-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Dimensionality Reduction</a></span></li><li><span><a href=\"#Generative-Models\" data-toc-modified-id=\"Generative-Models-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Generative Models</a></span></li><li><span><a href=\"#Anomaly-Detection-(outlier-detection)\" data-toc-modified-id=\"Anomaly-Detection-(outlier-detection)-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Anomaly Detection (outlier detection)</a></span></li><li><span><a href=\"#Association-Rule-Learning\" data-toc-modified-id=\"Association-Rule-Learning-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>Association Rule Learning</a></span></li><li><span><a href=\"#etc...\" data-toc-modified-id=\"etc...-2.2.6\"><span class=\"toc-item-num\">2.2.6&nbsp;&nbsp;</span>etc...</a></span></li></ul></li><li><span><a href=\"#Reinforcement-(Deep)-Learning\" data-toc-modified-id=\"Reinforcement-(Deep)-Learning-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Reinforcement (Deep) Learning</a></span></li><li><span><a href=\"#Learning-Strategies\" data-toc-modified-id=\"Learning-Strategies-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Learning Strategies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transfer-Learning\" data-toc-modified-id=\"Transfer-Learning-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Transfer Learning</a></span></li><li><span><a href=\"#Active-Learning\" data-toc-modified-id=\"Active-Learning-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Active Learning</a></span></li><li><span><a href=\"#Semi-supervised-Learning\" data-toc-modified-id=\"Semi-supervised-Learning-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Semi-supervised Learning</a></span></li><li><span><a href=\"#Ensemble-Learning\" data-toc-modified-id=\"Ensemble-Learning-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>Ensemble Learning</a></span></li></ul></li></ul></li><li><span><a href=\"#Neural-Networks\" data-toc-modified-id=\"Neural-Networks-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Layer\" data-toc-modified-id=\"Layer-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Layer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Input-Layer\" data-toc-modified-id=\"Input-Layer-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Input Layer</a></span></li><li><span><a href=\"#Hidden-Layers\" data-toc-modified-id=\"Hidden-Layers-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Hidden Layers</a></span></li><li><span><a href=\"#Output-Layer\" data-toc-modified-id=\"Output-Layer-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Output Layer</a></span></li></ul></li><li><span><a href=\"#Nodes/Neurons/Units\" data-toc-modified-id=\"Nodes/Neurons/Units-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Nodes/Neurons/Units</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Inputs\" data-toc-modified-id=\"1.-Inputs-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>1. Inputs</a></span></li><li><span><a href=\"#2.-Weighted-sum-(Weights-and-biases)\" data-toc-modified-id=\"2.-Weighted-sum-(Weights-and-biases)-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>2. Weighted sum (Weights and biases)</a></span></li><li><span><a href=\"#3.-Activation-Function\" data-toc-modified-id=\"3.-Activation-Function-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>3. Activation Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sigmoid-Function\" data-toc-modified-id=\"Sigmoid-Function-3.2.3.1\"><span class=\"toc-item-num\">3.2.3.1&nbsp;&nbsp;</span>Sigmoid Function</a></span></li><li><span><a href=\"#Softmax-Function\" data-toc-modified-id=\"Softmax-Function-3.2.3.2\"><span class=\"toc-item-num\">3.2.3.2&nbsp;&nbsp;</span>Softmax Function</a></span></li><li><span><a href=\"#Tanh-Function-(Hyperbolic-Tangent)\" data-toc-modified-id=\"Tanh-Function-(Hyperbolic-Tangent)-3.2.3.3\"><span class=\"toc-item-num\">3.2.3.3&nbsp;&nbsp;</span>Tanh Function (Hyperbolic Tangent)</a></span></li><li><span><a href=\"#ReLU-Function-(Rectified-Linear-Unit)\" data-toc-modified-id=\"ReLU-Function-(Rectified-Linear-Unit)-3.2.3.4\"><span class=\"toc-item-num\">3.2.3.4&nbsp;&nbsp;</span>ReLU Function (Rectified Linear Unit)</a></span></li><li><span><a href=\"#Leaky-ReLU-Function\" data-toc-modified-id=\"Leaky-ReLU-Function-3.2.3.5\"><span class=\"toc-item-num\">3.2.3.5&nbsp;&nbsp;</span>Leaky ReLU Function</a></span></li><li><span><a href=\"#etc...\" data-toc-modified-id=\"etc...-3.2.3.6\"><span class=\"toc-item-num\">3.2.3.6&nbsp;&nbsp;</span>etc...</a></span></li></ul></li><li><span><a href=\"#4.-Output\" data-toc-modified-id=\"4.-Output-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>4. Output</a></span></li></ul></li><li><span><a href=\"#Loss-function-/-Cost-function-/-Objective-function\" data-toc-modified-id=\"Loss-function-/-Cost-function-/-Objective-function-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Loss function / Cost function / Objective function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-Cross-Entropy-(Log-Loss)\" data-toc-modified-id=\"Binary-Cross-Entropy-(Log-Loss)-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Binary Cross-Entropy (Log Loss)</a></span></li><li><span><a href=\"#Categorical-Cross-Entropy\" data-toc-modified-id=\"Categorical-Cross-Entropy-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Categorical Cross-Entropy</a></span></li><li><span><a href=\"#Mean-Squared-Error-(MSE)\" data-toc-modified-id=\"Mean-Squared-Error-(MSE)-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Mean Squared Error (MSE)</a></span></li><li><span><a href=\"#Mean-Absolute-Error-(MAE)\" data-toc-modified-id=\"Mean-Absolute-Error-(MAE)-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Mean Absolute Error (MAE)</a></span></li><li><span><a href=\"#Huber-Loss\" data-toc-modified-id=\"Huber-Loss-3.3.5\"><span class=\"toc-item-num\">3.3.5&nbsp;&nbsp;</span>Huber Loss</a></span></li><li><span><a href=\"#etc...\" data-toc-modified-id=\"etc...-3.3.6\"><span class=\"toc-item-num\">3.3.6&nbsp;&nbsp;</span>etc...</a></span></li></ul></li><li><span><a href=\"#Backpropagation-(Backward-pass-/-Backward-propagation-of-errors)\" data-toc-modified-id=\"Backpropagation-(Backward-pass-/-Backward-propagation-of-errors)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Backpropagation (Backward pass / Backward propagation of errors)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optimizer-(update-step)\" data-toc-modified-id=\"Optimizer-(update-step)-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Optimizer (update step)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Batch-Gradient-Descent-(BGD)\" data-toc-modified-id=\"Batch-Gradient-Descent-(BGD)-3.4.1.1\"><span class=\"toc-item-num\">3.4.1.1&nbsp;&nbsp;</span>Batch Gradient Descent (BGD)</a></span></li><li><span><a href=\"#Stochastic-Gradient-Descent-(SGD)\" data-toc-modified-id=\"Stochastic-Gradient-Descent-(SGD)-3.4.1.2\"><span class=\"toc-item-num\">3.4.1.2&nbsp;&nbsp;</span>Stochastic Gradient Descent (SGD)</a></span></li><li><span><a href=\"#Mini-Batch-Gradient-Descent\" data-toc-modified-id=\"Mini-Batch-Gradient-Descent-3.4.1.3\"><span class=\"toc-item-num\">3.4.1.3&nbsp;&nbsp;</span>Mini-Batch Gradient Descent</a></span></li><li><span><a href=\"#RMSProp-(Root-Mean-Square-Propagation)\" data-toc-modified-id=\"RMSProp-(Root-Mean-Square-Propagation)-3.4.1.4\"><span class=\"toc-item-num\">3.4.1.4&nbsp;&nbsp;</span>RMSProp (Root Mean Square Propagation)</a></span></li><li><span><a href=\"#Adam-(Adaptive-Moment-Estimation)\" data-toc-modified-id=\"Adam-(Adaptive-Moment-Estimation)-3.4.1.5\"><span class=\"toc-item-num\">3.4.1.5&nbsp;&nbsp;</span>Adam (Adaptive Moment Estimation)</a></span></li><li><span><a href=\"#Momentum\" data-toc-modified-id=\"Momentum-3.4.1.6\"><span class=\"toc-item-num\">3.4.1.6&nbsp;&nbsp;</span>Momentum</a></span></li><li><span><a href=\"#etc...\" data-toc-modified-id=\"etc...-3.4.1.7\"><span class=\"toc-item-num\">3.4.1.7&nbsp;&nbsp;</span>etc...</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Layer-types\" data-toc-modified-id=\"Layer-types-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Layer types</a></span><ul class=\"toc-item\"><li><span><a href=\"#Activation-Layers\" data-toc-modified-id=\"Activation-Layers-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Activation Layers</a></span><ul class=\"toc-item\"><li><span><a href=\"#ReLU-Layer\" data-toc-modified-id=\"ReLU-Layer-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>ReLU Layer</a></span></li></ul></li><li><span><a href=\"#Dense-Layers-(FC-layers)-(fully-connected-layers)\" data-toc-modified-id=\"Dense-Layers-(FC-layers)-(fully-connected-layers)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Dense Layers (FC layers) (fully connected layers)</a></span></li><li><span><a href=\"#Flatten-Layer\" data-toc-modified-id=\"Flatten-Layer-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Flatten Layer</a></span></li><li><span><a href=\"#Pooling-Layer-([Max,-Average]Pooling[1,-2,-3]D\" data-toc-modified-id=\"Pooling-Layer-([Max,-Average]Pooling[1,-2,-3]D-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Pooling Layer ([Max, Average]Pooling[1, 2, 3]D</a></span><ul class=\"toc-item\"><li><span><a href=\"#Global-Average-Pooling-(GAP)\" data-toc-modified-id=\"Global-Average-Pooling-(GAP)-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Global Average Pooling (GAP)</a></span></li></ul></li><li><span><a href=\"#Convolutional-layers-(Conv[1,-2,-3]D)\" data-toc-modified-id=\"Convolutional-layers-(Conv[1,-2,-3]D)-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Convolutional layers (Conv[1, 2, 3]D)</a></span></li><li><span><a href=\"#Dropout-layer\" data-toc-modified-id=\"Dropout-layer-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Dropout layer</a></span></li></ul></li><li><span><a href=\"#Learning-dynamics\" data-toc-modified-id=\"Learning-dynamics-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Learning dynamics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Learning\" data-toc-modified-id=\"Learning-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Learning</a></span></li><li><span><a href=\"#Hypothesis-space\" data-toc-modified-id=\"Hypothesis-space-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Hypothesis space</a></span></li><li><span><a href=\"#Underfitting\" data-toc-modified-id=\"Underfitting-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Underfitting</a></span></li><li><span><a href=\"#Overfitting\" data-toc-modified-id=\"Overfitting-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Overfitting</a></span></li><li><span><a href=\"#Convergence\" data-toc-modified-id=\"Convergence-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Convergence</a></span></li><li><span><a href=\"#Gradient-Problems\" data-toc-modified-id=\"Gradient-Problems-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Gradient Problems</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vanishing-Gradient\" data-toc-modified-id=\"Vanishing-Gradient-5.6.1\"><span class=\"toc-item-num\">5.6.1&nbsp;&nbsp;</span>Vanishing Gradient</a></span></li><li><span><a href=\"#Exploding-Gradient\" data-toc-modified-id=\"Exploding-Gradient-5.6.2\"><span class=\"toc-item-num\">5.6.2&nbsp;&nbsp;</span>Exploding Gradient</a></span></li></ul></li><li><span><a href=\"#Hyperparameters\" data-toc-modified-id=\"Hyperparameters-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Learning-Rate\" data-toc-modified-id=\"Learning-Rate-5.7.1\"><span class=\"toc-item-num\">5.7.1&nbsp;&nbsp;</span>Learning Rate</a></span></li><li><span><a href=\"#Batch-(Batch-Size)\" data-toc-modified-id=\"Batch-(Batch-Size)-5.7.2\"><span class=\"toc-item-num\">5.7.2&nbsp;&nbsp;</span>Batch (Batch Size)</a></span></li><li><span><a href=\"#Epochs\" data-toc-modified-id=\"Epochs-5.7.3\"><span class=\"toc-item-num\">5.7.3&nbsp;&nbsp;</span>Epochs</a></span></li><li><span><a href=\"#Number-of-Layers\" data-toc-modified-id=\"Number-of-Layers-5.7.4\"><span class=\"toc-item-num\">5.7.4&nbsp;&nbsp;</span>Number of Layers</a></span></li><li><span><a href=\"#Number-of-Units-per-Layer\" data-toc-modified-id=\"Number-of-Units-per-Layer-5.7.5\"><span class=\"toc-item-num\">5.7.5&nbsp;&nbsp;</span>Number of Units per Layer</a></span></li><li><span><a href=\"#Weight-Initialization\" data-toc-modified-id=\"Weight-Initialization-5.7.6\"><span class=\"toc-item-num\">5.7.6&nbsp;&nbsp;</span>Weight Initialization</a></span></li><li><span><a href=\"#Activation-Function\" data-toc-modified-id=\"Activation-Function-5.7.7\"><span class=\"toc-item-num\">5.7.7&nbsp;&nbsp;</span>Activation Function</a></span></li><li><span><a href=\"#Optimizer\" data-toc-modified-id=\"Optimizer-5.7.8\"><span class=\"toc-item-num\">5.7.8&nbsp;&nbsp;</span>Optimizer</a></span></li><li><span><a href=\"#Loss-Function\" data-toc-modified-id=\"Loss-Function-5.7.9\"><span class=\"toc-item-num\">5.7.9&nbsp;&nbsp;</span>Loss Function</a></span></li><li><span><a href=\"#Regularization-Techniques-(Regularization-Parameters)\" data-toc-modified-id=\"Regularization-Techniques-(Regularization-Parameters)-5.7.10\"><span class=\"toc-item-num\">5.7.10&nbsp;&nbsp;</span>Regularization Techniques (Regularization Parameters)</a></span><ul class=\"toc-item\"><li><span><a href=\"#L1-and-L2-regularization\" data-toc-modified-id=\"L1-and-L2-regularization-5.7.10.1\"><span class=\"toc-item-num\">5.7.10.1&nbsp;&nbsp;</span>L1 and L2 regularization</a></span></li><li><span><a href=\"#Dropout\" data-toc-modified-id=\"Dropout-5.7.10.2\"><span class=\"toc-item-num\">5.7.10.2&nbsp;&nbsp;</span>Dropout</a></span></li><li><span><a href=\"#Early-stopping\" data-toc-modified-id=\"Early-stopping-5.7.10.3\"><span class=\"toc-item-num\">5.7.10.3&nbsp;&nbsp;</span>Early stopping</a></span></li><li><span><a href=\"#Data-Augmentation\" data-toc-modified-id=\"Data-Augmentation-5.7.10.4\"><span class=\"toc-item-num\">5.7.10.4&nbsp;&nbsp;</span>Data Augmentation</a></span></li><li><span><a href=\"#Batch-Normalization\" data-toc-modified-id=\"Batch-Normalization-5.7.10.5\"><span class=\"toc-item-num\">5.7.10.5&nbsp;&nbsp;</span>Batch Normalization</a></span></li><li><span><a href=\"#Noise-Injection\" data-toc-modified-id=\"Noise-Injection-5.7.10.6\"><span class=\"toc-item-num\">5.7.10.6&nbsp;&nbsp;</span>Noise Injection</a></span></li></ul></li><li><span><a href=\"#Momentum\" data-toc-modified-id=\"Momentum-5.7.11\"><span class=\"toc-item-num\">5.7.11&nbsp;&nbsp;</span>Momentum</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Model Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluation-Metrics\" data-toc-modified-id=\"Evaluation-Metrics-5.8.1\"><span class=\"toc-item-num\">5.8.1&nbsp;&nbsp;</span>Evaluation Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classification-Metrics\" data-toc-modified-id=\"Classification-Metrics-5.8.1.1\"><span class=\"toc-item-num\">5.8.1.1&nbsp;&nbsp;</span>Classification Metrics</a></span></li><li><span><a href=\"#Regression-Metrics\" data-toc-modified-id=\"Regression-Metrics-5.8.1.2\"><span class=\"toc-item-num\">5.8.1.2&nbsp;&nbsp;</span>Regression Metrics</a></span></li></ul></li><li><span><a href=\"#Bias-Variance-Tradeoff\" data-toc-modified-id=\"Bias-Variance-Tradeoff-5.8.2\"><span class=\"toc-item-num\">5.8.2&nbsp;&nbsp;</span>Bias-Variance Tradeoff</a></span><ul class=\"toc-item\"><li><span><a href=\"#Regularization\" data-toc-modified-id=\"Regularization-5.8.2.1\"><span class=\"toc-item-num\">5.8.2.1&nbsp;&nbsp;</span>Regularization</a></span></li><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-5.8.2.2\"><span class=\"toc-item-num\">5.8.2.2&nbsp;&nbsp;</span>Cross-Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#K-fold\" data-toc-modified-id=\"K-fold-5.8.2.2.1\"><span class=\"toc-item-num\">5.8.2.2.1&nbsp;&nbsp;</span>K-fold</a></span></li><li><span><a href=\"#Leave-One-Out-Cross-Validation-(LOOCV)\" data-toc-modified-id=\"Leave-One-Out-Cross-Validation-(LOOCV)-5.8.2.2.2\"><span class=\"toc-item-num\">5.8.2.2.2&nbsp;&nbsp;</span>Leave One Out Cross Validation (LOOCV)</a></span></li><li><span><a href=\"#Stratified-K-Fold-Cross-Validation\" data-toc-modified-id=\"Stratified-K-Fold-Cross-Validation-5.8.2.2.3\"><span class=\"toc-item-num\">5.8.2.2.3&nbsp;&nbsp;</span>Stratified K-Fold Cross Validation</a></span></li><li><span><a href=\"#Time-Series-Cross-Validation.\" data-toc-modified-id=\"Time-Series-Cross-Validation.-5.8.2.2.4\"><span class=\"toc-item-num\">5.8.2.2.4&nbsp;&nbsp;</span>Time-Series Cross-Validation.</a></span></li><li><span><a href=\"#etc...\" data-toc-modified-id=\"etc...-5.8.2.2.5\"><span class=\"toc-item-num\">5.8.2.2.5&nbsp;&nbsp;</span>etc...</a></span></li></ul></li></ul></li><li><span><a href=\"#Ensemble-Methods-(Ensemble-Learning)\" data-toc-modified-id=\"Ensemble-Methods-(Ensemble-Learning)-5.8.3\"><span class=\"toc-item-num\">5.8.3&nbsp;&nbsp;</span>Ensemble Methods (Ensemble Learning)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bagging\" data-toc-modified-id=\"Bagging-5.8.3.1\"><span class=\"toc-item-num\">5.8.3.1&nbsp;&nbsp;</span>Bagging</a></span></li><li><span><a href=\"#Boosting\" data-toc-modified-id=\"Boosting-5.8.3.2\"><span class=\"toc-item-num\">5.8.3.2&nbsp;&nbsp;</span>Boosting</a></span></li><li><span><a href=\"#Stacking\" data-toc-modified-id=\"Stacking-5.8.3.3\"><span class=\"toc-item-num\">5.8.3.3&nbsp;&nbsp;</span>Stacking</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-tuning\" data-toc-modified-id=\"Model-tuning-5.9\"><span class=\"toc-item-num\">5.9&nbsp;&nbsp;</span>Model tuning</a></span></li></ul></li><li><span><a href=\"#Architecture-models\" data-toc-modified-id=\"Architecture-models-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Architecture models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fundamentals\" data-toc-modified-id=\"Fundamentals-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Fundamentals</a></span><ul class=\"toc-item\"><li><span><a href=\"#Perceptron-(P-layer)\" data-toc-modified-id=\"Perceptron-(P-layer)-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Perceptron (P-layer)</a></span></li><li><span><a href=\"#Multilayer-Perceptron-(MLP)\" data-toc-modified-id=\"Multilayer-Perceptron-(MLP)-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Multilayer Perceptron (MLP)</a></span></li><li><span><a href=\"#Deep-Neural-Networks-(DNNs)\" data-toc-modified-id=\"Deep-Neural-Networks-(DNNs)-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>Deep Neural Networks (DNNs)</a></span></li><li><span><a href=\"#Feedforward-Neural-Networks-(FNNs)\" data-toc-modified-id=\"Feedforward-Neural-Networks-(FNNs)-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;</span>Feedforward Neural Networks (FNNs)</a></span></li></ul></li><li><span><a href=\"#Convolutional-Architectures\" data-toc-modified-id=\"Convolutional-Architectures-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Convolutional Architectures</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Filters\" data-toc-modified-id=\"Filters-6.2.0.1\"><span class=\"toc-item-num\">6.2.0.1&nbsp;&nbsp;</span>Filters</a></span></li></ul></li><li><span><a href=\"#Convolutional-Neural-Networks-(ConvNets)-(CNNs)\" data-toc-modified-id=\"Convolutional-Neural-Networks-(ConvNets)-(CNNs)-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Convolutional Neural Networks (ConvNets) (CNNs)</a></span></li><li><span><a href=\"#Residual-Network-(ResNet)\" data-toc-modified-id=\"Residual-Network-(ResNet)-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Residual Network (ResNet)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Residual-connections-(skip-connections)-(shortcut-connection)\" data-toc-modified-id=\"Residual-connections-(skip-connections)-(shortcut-connection)-6.2.2.1\"><span class=\"toc-item-num\">6.2.2.1&nbsp;&nbsp;</span>Residual connections (skip connections) (shortcut connection)</a></span></li></ul></li></ul></li><li><span><a href=\"#Recurrent-Architectures\" data-toc-modified-id=\"Recurrent-Architectures-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Recurrent Architectures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recurrent-Neural-Networks-(RNNs)\" data-toc-modified-id=\"Recurrent-Neural-Networks-(RNNs)-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Recurrent Neural Networks (RNNs)</a></span></li><li><span><a href=\"#Long-Short-Term-Memory-Networks-(LSTMs)\" data-toc-modified-id=\"Long-Short-Term-Memory-Networks-(LSTMs)-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Long Short-Term Memory Networks (LSTMs)</a></span></li><li><span><a href=\"#Sequence-to-Sequence-(Seq2Seq)\" data-toc-modified-id=\"Sequence-to-Sequence-(Seq2Seq)-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>Sequence-to-Sequence (Seq2Seq)</a></span></li></ul></li><li><span><a href=\"#Generative-Models\" data-toc-modified-id=\"Generative-Models-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Generative Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Autoencoder-(AEs)\" data-toc-modified-id=\"Autoencoder-(AEs)-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>Autoencoder (AEs)</a></span></li><li><span><a href=\"#Generative-Adversarial-Networks-(GANs)\" data-toc-modified-id=\"Generative-Adversarial-Networks-(GANs)-6.4.2\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>Generative Adversarial Networks (GANs)</a></span></li></ul></li><li><span><a href=\"#Transformer-Networks-(attention-mechanisms)\" data-toc-modified-id=\"Transformer-Networks-(attention-mechanisms)-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Transformer Networks (attention mechanisms)</a></span><ul class=\"toc-item\"><li><span><a href=\"#BERT-(Bidirectional-Encoder-Representations-from-Transformers)\" data-toc-modified-id=\"BERT-(Bidirectional-Encoder-Representations-from-Transformers)-6.5.1\"><span class=\"toc-item-num\">6.5.1&nbsp;&nbsp;</span>BERT (Bidirectional Encoder Representations from Transformers)</a></span></li><li><span><a href=\"#GPT-(Generative-Pretrained-Transformer)\" data-toc-modified-id=\"GPT-(Generative-Pretrained-Transformer)-6.5.2\"><span class=\"toc-item-num\">6.5.2&nbsp;&nbsp;</span>GPT (Generative Pretrained Transformer)</a></span></li></ul></li><li><span><a href=\"#Other-Architectures\" data-toc-modified-id=\"Other-Architectures-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>Other Architectures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multi-Stream-Network-(Multi-Input)\" data-toc-modified-id=\"Multi-Stream-Network-(Multi-Input)-6.6.1\"><span class=\"toc-item-num\">6.6.1&nbsp;&nbsp;</span>Multi-Stream Network (Multi-Input)</a></span></li><li><span><a href=\"#Graph-Neural-Network-(GNN)\" data-toc-modified-id=\"Graph-Neural-Network-(GNN)-6.6.2\"><span class=\"toc-item-num\">6.6.2&nbsp;&nbsp;</span>Graph Neural Network (GNN)</a></span></li><li><span><a href=\"#etc...\" data-toc-modified-id=\"etc...-6.6.3\"><span class=\"toc-item-num\">6.6.3&nbsp;&nbsp;</span>etc...</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-representation\" data-toc-modified-id=\"Data-representation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Data representation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Type-of-data\" data-toc-modified-id=\"Type-of-data-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Type of data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scalar\" data-toc-modified-id=\"Scalar-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Scalar</a></span></li><li><span><a href=\"#Vector\" data-toc-modified-id=\"Vector-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>Vector</a></span></li><li><span><a href=\"#Matrice\" data-toc-modified-id=\"Matrice-7.1.3\"><span class=\"toc-item-num\">7.1.3&nbsp;&nbsp;</span>Matrice</a></span></li><li><span><a href=\"#Tensor\" data-toc-modified-id=\"Tensor-7.1.4\"><span class=\"toc-item-num\">7.1.4&nbsp;&nbsp;</span>Tensor</a></span></li><li><span><a href=\"#Numerical-Data\" data-toc-modified-id=\"Numerical-Data-7.1.5\"><span class=\"toc-item-num\">7.1.5&nbsp;&nbsp;</span>Numerical Data</a></span></li><li><span><a href=\"#Categorical-Data-(qualitative-data)\" data-toc-modified-id=\"Categorical-Data-(qualitative-data)-7.1.6\"><span class=\"toc-item-num\">7.1.6&nbsp;&nbsp;</span>Categorical Data (qualitative data)</a></span></li><li><span><a href=\"#Ordinal-Data\" data-toc-modified-id=\"Ordinal-Data-7.1.7\"><span class=\"toc-item-num\">7.1.7&nbsp;&nbsp;</span>Ordinal Data</a></span></li><li><span><a href=\"#Text-Data\" data-toc-modified-id=\"Text-Data-7.1.8\"><span class=\"toc-item-num\">7.1.8&nbsp;&nbsp;</span>Text Data</a></span></li><li><span><a href=\"#Time-Series-Data\" data-toc-modified-id=\"Time-Series-Data-7.1.9\"><span class=\"toc-item-num\">7.1.9&nbsp;&nbsp;</span>Time-Series Data</a></span></li><li><span><a href=\"#Image-Data\" data-toc-modified-id=\"Image-Data-7.1.10\"><span class=\"toc-item-num\">7.1.10&nbsp;&nbsp;</span>Image Data</a></span></li><li><span><a href=\"#Audio-Data\" data-toc-modified-id=\"Audio-Data-7.1.11\"><span class=\"toc-item-num\">7.1.11&nbsp;&nbsp;</span>Audio Data</a></span></li><li><span><a href=\"#Video-Data\" data-toc-modified-id=\"Video-Data-7.1.12\"><span class=\"toc-item-num\">7.1.12&nbsp;&nbsp;</span>Video Data</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-of-Information\" data-toc-modified-id=\"Loss-of-Information-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Loss of Information</a></span></li><li><span><a href=\"#Numerical-Encoding\" data-toc-modified-id=\"Numerical-Encoding-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Numerical Encoding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ordinal-Encoding\" data-toc-modified-id=\"Ordinal-Encoding-7.2.2.1\"><span class=\"toc-item-num\">7.2.2.1&nbsp;&nbsp;</span>Ordinal Encoding</a></span></li><li><span><a href=\"#One-Hot-Encoding\" data-toc-modified-id=\"One-Hot-Encoding-7.2.2.2\"><span class=\"toc-item-num\">7.2.2.2&nbsp;&nbsp;</span>One-Hot Encoding</a></span></li></ul></li><li><span><a href=\"#Scaling\" data-toc-modified-id=\"Scaling-7.2.3\"><span class=\"toc-item-num\">7.2.3&nbsp;&nbsp;</span>Scaling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalization-(Min-Max-scaling)-(Normalization-layers)\" data-toc-modified-id=\"Normalization-(Min-Max-scaling)-(Normalization-layers)-7.2.3.1\"><span class=\"toc-item-num\">7.2.3.1&nbsp;&nbsp;</span>Normalization (Min-Max scaling) (Normalization layers)</a></span></li><li><span><a href=\"#Standardization\" data-toc-modified-id=\"Standardization-7.2.3.2\"><span class=\"toc-item-num\">7.2.3.2&nbsp;&nbsp;</span>Standardization</a></span></li></ul></li><li><span><a href=\"#Embedding\" data-toc-modified-id=\"Embedding-7.2.4\"><span class=\"toc-item-num\">7.2.4&nbsp;&nbsp;</span>Embedding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-7.2.4.1\"><span class=\"toc-item-num\">7.2.4.1&nbsp;&nbsp;</span>Word2Vec</a></span></li><li><span><a href=\"#GloVe\" data-toc-modified-id=\"GloVe-7.2.4.2\"><span class=\"toc-item-num\">7.2.4.2&nbsp;&nbsp;</span>GloVe</a></span></li><li><span><a href=\"#FastText\" data-toc-modified-id=\"FastText-7.2.4.3\"><span class=\"toc-item-num\">7.2.4.3&nbsp;&nbsp;</span>FastText</a></span></li><li><span><a href=\"#Embedding-Layer-in-Neural-Networks\" data-toc-modified-id=\"Embedding-Layer-in-Neural-Networks-7.2.4.4\"><span class=\"toc-item-num\">7.2.4.4&nbsp;&nbsp;</span>Embedding Layer in Neural Networks</a></span></li><li><span><a href=\"#Semantic-Relationships-in-Embeddings\" data-toc-modified-id=\"Semantic-Relationships-in-Embeddings-7.2.4.5\"><span class=\"toc-item-num\">7.2.4.5&nbsp;&nbsp;</span>Semantic Relationships in Embeddings</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Data Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removing-Duplicate-Entries\" data-toc-modified-id=\"Removing-Duplicate-Entries-7.3.1\"><span class=\"toc-item-num\">7.3.1&nbsp;&nbsp;</span>Removing Duplicate Entries</a></span></li><li><span><a href=\"#Data-Validation\" data-toc-modified-id=\"Data-Validation-7.3.2\"><span class=\"toc-item-num\">7.3.2&nbsp;&nbsp;</span>Data Validation</a></span></li><li><span><a href=\"#Correcting-Inconsistencies\" data-toc-modified-id=\"Correcting-Inconsistencies-7.3.3\"><span class=\"toc-item-num\">7.3.3&nbsp;&nbsp;</span>Correcting Inconsistencies</a></span></li><li><span><a href=\"#Noise-Reduction\" data-toc-modified-id=\"Noise-Reduction-7.3.4\"><span class=\"toc-item-num\">7.3.4&nbsp;&nbsp;</span>Noise Reduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-7.3.4.1\"><span class=\"toc-item-num\">7.3.4.1&nbsp;&nbsp;</span>Filtering</a></span></li><li><span><a href=\"#Binning\" data-toc-modified-id=\"Binning-7.3.4.2\"><span class=\"toc-item-num\">7.3.4.2&nbsp;&nbsp;</span>Binning</a></span></li><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-7.3.4.3\"><span class=\"toc-item-num\">7.3.4.3&nbsp;&nbsp;</span>Regression</a></span></li><li><span><a href=\"#Robust-Methods\" data-toc-modified-id=\"Robust-Methods-7.3.4.4\"><span class=\"toc-item-num\">7.3.4.4&nbsp;&nbsp;</span>Robust Methods</a></span></li><li><span><a href=\"#Image-denoising\" data-toc-modified-id=\"Image-denoising-7.3.4.5\"><span class=\"toc-item-num\">7.3.4.5&nbsp;&nbsp;</span>Image denoising</a></span></li><li><span><a href=\"#Outlier-Detection-and-Handling\" data-toc-modified-id=\"Outlier-Detection-and-Handling-7.3.4.6\"><span class=\"toc-item-num\">7.3.4.6&nbsp;&nbsp;</span>Outlier Detection and Handling</a></span></li></ul></li><li><span><a href=\"#Handling-Missing-Values\" data-toc-modified-id=\"Handling-Missing-Values-7.3.5\"><span class=\"toc-item-num\">7.3.5&nbsp;&nbsp;</span>Handling Missing Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imputation\" data-toc-modified-id=\"Imputation-7.3.5.1\"><span class=\"toc-item-num\">7.3.5.1&nbsp;&nbsp;</span>Imputation</a></span></li><li><span><a href=\"#Deletion\" data-toc-modified-id=\"Deletion-7.3.5.2\"><span class=\"toc-item-num\">7.3.5.2&nbsp;&nbsp;</span>Deletion</a></span></li></ul></li></ul></li><li><span><a href=\"#Dimensionality-Reduction\" data-toc-modified-id=\"Dimensionality-Reduction-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Dimensionality Reduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feature-Extraction\" data-toc-modified-id=\"Feature-Extraction-7.4.1\"><span class=\"toc-item-num\">7.4.1&nbsp;&nbsp;</span>Feature Extraction</a></span></li><li><span><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-7.4.2\"><span class=\"toc-item-num\">7.4.2&nbsp;&nbsp;</span>Feature Selection</a></span></li><li><span><a href=\"#Flatten-Tensor\" data-toc-modified-id=\"Flatten-Tensor-7.4.3\"><span class=\"toc-item-num\">7.4.3&nbsp;&nbsp;</span>Flatten Tensor</a></span></li></ul></li></ul></li><li><span><a href=\"#APIs\" data-toc-modified-id=\"APIs-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>APIs</a></span><ul class=\"toc-item\"><li><span><a href=\"#NumPy-(Numerical-Python)\" data-toc-modified-id=\"NumPy-(Numerical-Python)-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>NumPy (Numerical Python)</a></span></li><li><span><a href=\"#Pandas\" data-toc-modified-id=\"Pandas-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Pandas</a></span></li><li><span><a href=\"#Keras\" data-toc-modified-id=\"Keras-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Keras</a></span></li><li><span><a href=\"#Tensorflow\" data-toc-modified-id=\"Tensorflow-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Tensorflow</a></span></li><li><span><a href=\"#PyTorch\" data-toc-modified-id=\"PyTorch-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>PyTorch</a></span></li></ul></li><li><span><a href=\"#Applications-(Python-Keras)\" data-toc-modified-id=\"Applications-(Python-Keras)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Applications (Python Keras)</a></span><ul class=\"toc-item\"><li><span><a href=\"#MNIST-(Modified-National-Institute-of-Standards-and-Technology)\" data-toc-modified-id=\"MNIST-(Modified-National-Institute-of-Standards-and-Technology)-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>MNIST (Modified National Institute of Standards and Technology)</a></span><ul class=\"toc-item\"><li><span><a href=\"#A-straightforward-and-highly-accurate-solution\" data-toc-modified-id=\"A-straightforward-and-highly-accurate-solution-9.1.1\"><span class=\"toc-item-num\">9.1.1&nbsp;&nbsp;</span>A straightforward and highly accurate solution</a></span></li><li><span><a href=\"#.reshape\" data-toc-modified-id=\".reshape-9.1.2\"><span class=\"toc-item-num\">9.1.2&nbsp;&nbsp;</span>.reshape</a></span></li><li><span><a href=\"#.astype(float32)\" data-toc-modified-id=\".astype(float32)-9.1.3\"><span class=\"toc-item-num\">9.1.3&nbsp;&nbsp;</span>.astype(float32)</a></span></li><li><span><a href=\"#/-255\" data-toc-modified-id=\"/-255-9.1.4\"><span class=\"toc-item-num\">9.1.4&nbsp;&nbsp;</span>/ 255</a></span></li><li><span><a href=\"#to_categorical()\" data-toc-modified-id=\"to_categorical()-9.1.5\"><span class=\"toc-item-num\">9.1.5&nbsp;&nbsp;</span>to_categorical()</a></span></li><li><span><a href=\"#models.Sequential()\" data-toc-modified-id=\"models.Sequential()-9.1.6\"><span class=\"toc-item-num\">9.1.6&nbsp;&nbsp;</span>models.Sequential()</a></span></li><li><span><a href=\"#layers.Dense()\" data-toc-modified-id=\"layers.Dense()-9.1.7\"><span class=\"toc-item-num\">9.1.7&nbsp;&nbsp;</span>layers.Dense()</a></span></li><li><span><a href=\"#model.add()\" data-toc-modified-id=\"model.add()-9.1.8\"><span class=\"toc-item-num\">9.1.8&nbsp;&nbsp;</span>model.add()</a></span></li><li><span><a href=\"#model.summary()\" data-toc-modified-id=\"model.summary()-9.1.9\"><span class=\"toc-item-num\">9.1.9&nbsp;&nbsp;</span>model.summary()</a></span></li><li><span><a href=\"#model.compile()\" data-toc-modified-id=\"model.compile()-9.1.10\"><span class=\"toc-item-num\">9.1.10&nbsp;&nbsp;</span>model.compile()</a></span></li><li><span><a href=\"#model.fit()\" data-toc-modified-id=\"model.fit()-9.1.11\"><span class=\"toc-item-num\">9.1.11&nbsp;&nbsp;</span>model.fit()</a></span></li><li><span><a href=\"#model.predict()\" data-toc-modified-id=\"model.predict()-9.1.12\"><span class=\"toc-item-num\">9.1.12&nbsp;&nbsp;</span>model.predict()</a></span></li><li><span><a href=\"#model.evaluate()\" data-toc-modified-id=\"model.evaluate()-9.1.13\"><span class=\"toc-item-num\">9.1.13&nbsp;&nbsp;</span>model.evaluate()</a></span></li></ul></li><li><span><a href=\"#CIFAR-10-(Canadian-Institute-For-Advanced-Research-with-10-different-classes)\" data-toc-modified-id=\"CIFAR-10-(Canadian-Institute-For-Advanced-Research-with-10-different-classes)-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>CIFAR-10 (Canadian Institute For Advanced Research with 10 different classes)</a></span><ul class=\"toc-item\"><li><span><a href=\"#A-straightforward-and-lower-accurate-solution\" data-toc-modified-id=\"A-straightforward-and-lower-accurate-solution-9.2.1\"><span class=\"toc-item-num\">9.2.1&nbsp;&nbsp;</span>A straightforward and lower accurate solution</a></span><ul class=\"toc-item\"><li><span><a href=\"#EarlyStopping()\" data-toc-modified-id=\"EarlyStopping()-9.2.1.1\"><span class=\"toc-item-num\">9.2.1.1&nbsp;&nbsp;</span>EarlyStopping()</a></span></li></ul></li><li><span><a href=\"#Convolutional-Neural-Network-solutions\" data-toc-modified-id=\"Convolutional-Neural-Network-solutions-9.2.2\"><span class=\"toc-item-num\">9.2.2&nbsp;&nbsp;</span>Convolutional Neural Network solutions</a></span><ul class=\"toc-item\"><li><span><a href=\"#layers.Conv2D()\" data-toc-modified-id=\"layers.Conv2D()-9.2.2.1\"><span class=\"toc-item-num\">9.2.2.1&nbsp;&nbsp;</span>layers.Conv2D()</a></span></li><li><span><a href=\"#layers.MaxPooling2D()\" data-toc-modified-id=\"layers.MaxPooling2D()-9.2.2.2\"><span class=\"toc-item-num\">9.2.2.2&nbsp;&nbsp;</span>layers.MaxPooling2D()</a></span></li><li><span><a href=\"#VGG16\" data-toc-modified-id=\"VGG16-9.2.2.3\"><span class=\"toc-item-num\">9.2.2.3&nbsp;&nbsp;</span>VGG16</a></span></li><li><span><a href=\"#MobileNetV2\" data-toc-modified-id=\"MobileNetV2-9.2.2.4\"><span class=\"toc-item-num\">9.2.2.4&nbsp;&nbsp;</span>MobileNetV2</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc18494",
   "metadata": {},
   "source": [
    "# Fields\n",
    "\n",
    "## Artificial Intelligence (AI)\n",
    "Artificial Intelligence is a branch of computer science that aims to create machines and software that exhibit intelligent behavior. It's the broadest term, encompassing any artificial technique that enables computers to mimic human intelligence, using logic, if-then rules, decision trees, and machine learning. It also includes many more approaches that don‚Äôt involve any learning (symbolic AI). The Turing test is the key concepts that come to shape AI.\n",
    "\n",
    "### Artificial General Intelligence (AGI)\n",
    "A type of artificial intelligence that has the ability to understand, learn, apply knowledge, and improve its own capabilities. An AGI can perform any intellectual task that a human being can.\n",
    "\n",
    "### Singularity\n",
    "A hypothetical future point in time when technological growth becomes uncontrollable and irreversible, leading to unforeseeable changes to human civilization.\n",
    "\n",
    "This is based on the belief that an upgradable intelligent agent (such as an AGI with ability to self-improve) would enter a \"runaway reaction\" of self-improvement cycles, each new and more intelligent generation appearing more and more rapidly, causing an intelligence explosion and resulting in a powerful superintelligence that qualitatively far surpasses all human intelligence.\n",
    "\n",
    "### Alignment\n",
    "A term that refers to the problem of ensuring that artificial intelligence and machine learning systems behave in ways that are beneficial to humans and don't harm humanity or act in unintended ways.\n",
    "\n",
    "## Machine learning (ML)\n",
    "Machine learning is a subset of artificial intelligence that focuses on the development of algorithms and statistical models for solving problems for which development of algorithms by human programmers would be cost-prohibitive. That enable computers to perform tasks without being explicitly programmed to do so. These models are \"trained\" on data, learning from it and making predictions or decisions based on patterns they recognize in the data.\n",
    "\n",
    "A machine-learning model transforms its input data into meaningful outputs, a process that is learned from exposure to known examples of inputs and outputs. Therefore, the central problem is to meaningfully transform data: in other words, to learn useful representations of the input data at hand.\n",
    "\n",
    "Different type of machine learning methods exist like Support Vector Machines (SVMs), Deep learning (DL), Linear Regression, Decision Trees, Supervised Learning...\n",
    "\n",
    "## Artificial Neural Networks (ANNs)\n",
    "ANNs are computing systems inspired by biological neural networks, such as the ones in our brains. They are composed of interconnected nodes (analogous to neurons) that transmit signals to each other. These signals are processed by each node, and this process can \"learn\" to recognize patterns in data.<br>The simplest form of an ANN is the perceptron, which has only one layer of nodes. More complex ANNs may have multiple layers, and these are known as Multi-Layer Perceptrons (MLPs). (NNs also exist, the term \"artificial\" is used to distinguish them from biological neural networks).\n",
    "\n",
    "## Deep Learning (DL)\n",
    "Deep learning is a subset of machine learning that specifically focuses on ANNs with multiple layers. It's particularly effective at recognizing patterns. It employs neural networks with multiple layers (\"deep\" refers to the depth of structures) to model and understand complex patterns in datasets. These deep neural networks often model high-level abstractions in data, like recognizing objects in images or recognizing the semantics of words in sentences. Deep learning is simply a mathematical framework for learning representations from data. It's technically a multistage way to learn data representations.\n",
    "\n",
    "![machine-learning-vs-deep-learning](aivsmachinevsdeep.png) image source https://www.scs.org.sg/articles/machine-learning-vs-deep-learning\n",
    "\n",
    "## Shallow learning\n",
    "Refers to machine learning methods that are not based on multi-layer neural networks. These algorithms typically involve direct predictions from input features without passing them through multiple (more than two) non-linear transformations (or layers) as in deep learning.\n",
    "\n",
    "## Natural Language Processing (NLP)\n",
    "NLP is a subfield of AI that focuses on the interaction between humans and computers using natural language. The primary goal of NLP is to enable machines to understand, interpret, generate, and interact in human language in a valuable and meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6454b",
   "metadata": {},
   "source": [
    "# Learning algorithms\n",
    "Learning algorithms are the mathematical procedures that machine learning systems use to adjust their parameters based on data. They guide the machine learning model in the process of learning from data and improving its performance. Deep learning is able to implement those algorithms by using deep neural networks models. When the algorithm is used on the deep learning field, it's specified on the name.\n",
    "\n",
    "## Supervised (Deep) Learning\n",
    "A learning model that learns from a labeled dataset and then uses that learning to predict outcomes for unseen data. It's called \"supervised\" because the learning process is guided by the labels provided in the training data. This is the most common application of deep learning.\n",
    "\n",
    "![Supervised Learning.png](supervised_learning.png)\n",
    "image source https://www.v7labs.com/blog/supervised-vs-unsupervised-learning\n",
    "\n",
    "There are two main areas where supervised machine learning comes: classification problems and regression problems.\n",
    "\n",
    "### Classification problems\n",
    "The objective is to predict the class or category of an object or sample based on its features. The output falls into a finite set of possible categories.\n",
    "+ Binary classification refers to a situation where the output can be classified into two categories.\n",
    "+ Multiclass classification refers to a situation where the output can be classified into more than two categories.\n",
    "+ Multilabel classification refers to a situation where an output may belong into multiple categories.\n",
    "\n",
    "Multilabel classification may be used with binary and multiclass classifications.<br>\n",
    "Examples: email spam detection, cat/dog detection, object detection, sentiment classification...\n",
    "\n",
    "### Regression problems\n",
    "The objective is to predict a continuous numerical value based on input features. The output or target variable is a continuous number or a vector of numbers.\n",
    "\n",
    "Examples: predicting house price, temperature, stock market price, energy consumption...\n",
    "\n",
    "####  Lineare regression\n",
    "Linear regression is used to model the relationship between a dependent variable (also known as the target variable) and one or more independent variables (also known as features or predictors). The goal of linear regression is to find the best-fitting straight line through the data points. This line is formally known as the regression line. Linear regression is widely used in both statistics and machine learning for tasks such as predicting sales, estimating house prices, and many more. It's a simple yet powerful model, especially when your data is linearly separable. However, it might not perform well if your data isn't linear or has complex nonlinear relationships.\n",
    "\n",
    "It forms the basis of the simplest form of a neural network, (the single-layer perceptron) Deep learning models often employ linear transformations as components of the model, particularly within individual neurons in a layer, but these are combined with non-linear activation functions and arranged in multiple layers to enable the model to learn complex patterns.\n",
    "\n",
    "![classification-vs-regression.png](classification-vs-regression.png)\n",
    "image source https://www.v7labs.com/blog/supervised-vs-unsupervised-learning\n",
    "\n",
    "## Unsupervised (Deep) Learning\n",
    "A learning model that identifies patterns in data without the use of pre-existing labels, or where the model isn't provided with the correct results during training. This means that the model must learn to extract useful features and detect patterns in the input data on its own. Unlike supervised learning, the model isn't being guided by \"correct\" answers. Instead, it's finding its own structure in the input data. Unsupervised deep learning can be especially useful when dealing with large and complex datasets where labels are not available or are expensive to obtain.\n",
    "\n",
    "![Unsupervised Learning.png](unsupervised_machine_learning.png)\n",
    "image source https://www.v7labs.com/blog/supervised-vs-unsupervised-learning\n",
    "\n",
    "Unsupervised learning can be divided into several technical categories:\n",
    "\n",
    "### Clustering\n",
    "Clustering is the task of dividing the input data into groups based on their similarities or differences. The goal is to partition the data into clusters such that elements in the same cluster are more similar to each other than to those in other clusters.\n",
    "\n",
    "### Dimensionality Reduction\n",
    "Dimensionality reduction is used to reduce the number of variables in a dataset while preserving the essential features. It's often used for visualization purposes, feature extraction, or as a preprocessing step to make further analysis or machine learning more efficient.\n",
    "\n",
    "### Generative Models\n",
    "Generative models learn the joint probability distribution of the input data, and can generate new data that resembles the training data.\n",
    "\n",
    "### Anomaly Detection (outlier detection)\n",
    "Anomaly detection is a process of identifying data points or patterns that deviate significantly from the expected behavior. These identified anomalies often represent critical information in various application domains.\n",
    "\n",
    "### Association Rule Learning\n",
    "Association rule learning is a technique is used to discover interesting relations between variables in large databases.\n",
    "\n",
    "### etc...\n",
    "\n",
    "## Reinforcement (Deep) Learning\n",
    "A type of machine learning where an agent learns to make decisions by interacting with its environment. The agent is rewarded or penalized with points for correct or incorrect actions. Through this process, the agent learns a policy, which is a strategy for choosing actions that maximize its total reward over time.<br>The goal of the agent is to maximize the cumulative reward over time, which involves balancing exploration (trying out new actions to see their effects) and exploitation (choosing the actions that it knows have worked well in the past).\n",
    "\n",
    "Reinforcement Learning are composed of\n",
    "\n",
    "+ Agent: This is the decision-maker or the learner in the system.\n",
    "+ Environment: Everything outside the agent, with which the agent interacts.\n",
    "+ Actions (A): What an agent can do. For example, in a game of chess, an action would be moving a piece.\n",
    "+ States (S): The situations in which the agent finds itself. A state is a concrete and immediate situation that the agent encounters in the interaction loop.\n",
    "+ Reward (R): The feedback that the agent receives as a result of its action. A reward can be positive (for good actions) or negative (for bad actions).\n",
    "+ Policy (œÄ): The strategy that the agent employs to determine the next action based on the current state.\n",
    "+ Value Function: It estimates how good it is for an agent to be in a certain state, considering future rewards.\n",
    "+ Q-function (or Action-Value function): It estimates how good it is for an agent to take a certain action when in a certain state, considering future rewards.\n",
    "\n",
    "Examples: Game playing, robotics, education, finance, ...\n",
    "\n",
    "![rehenforcement_deep_learning.png](rehenforcement_deep_learning.png)\n",
    "image source https://www.v7labs.com/blog/supervised-vs-unsupervised-learning\n",
    "\n",
    "---\n",
    "![Types of learning in_Machine Learning.png](types_of_learning_in_Machine_Learning.png)\n",
    "image source https://www.v7labs.com/blog/supervised-vs-unsupervised-learning\n",
    "\n",
    "## Learning Strategies\n",
    "Learning Strategies can be applied across Supervised, Unsupervised, and Reinforcement Learning. They are strategies or approaches within those learning types.\n",
    "\n",
    "### Transfer Learning\n",
    "Transfer learning is a popular technique in machine learning and deep learning where a pre-trained model is adapted for a different but related problem. It's useful because training deep learning models from scratch requires a lot of data and computational resources, which is not always feasible. The main idea behind transfer learning is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world or textual world. You can then leverage these learned feature maps without having to start from scratch by training a large model on a large dataset. Transfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n",
    "\n",
    "Example<br> Let's consider you're building a model to identify different types of dogs. This can be quite challenging, considering the number of breeds, variations within a breed, and similarities between some breeds. However, you don't have to start from scratch. Instead, you can use a pre-trained Convolutional Neural Network (CNN) like VGG16, ResNet, or Inception, which have already been trained on a very large dataset, like ImageNet. These models have seen millions of images and learned to identify thousands of different categories, including many breeds of dogs. They have learned to recognize edges, corners, textures, and other low-level features in their early layers, and more complex concepts in the later layers.\n",
    "\n",
    "The most common incarnation of transfer learning in the context of deep learning is the following workflow\n",
    "+ Take layers from a previously trained model.\n",
    "+ Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n",
    "+ Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n",
    "+ Train the new layers on your dataset.\n",
    "A last, optional step, is fine-tuning, which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate. This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data.\n",
    "\n",
    "### Active Learning\n",
    "Active learning is a learning algorithm that is able to interactively query the user (or some other information source) to obtain the desired outputs at new data points. In traditional machine learning settings, an algorithm has access to a set of examples with associated labels, and it uses this information to learn a model that can make predictions on unseen instances. In many practical situations, obtaining labels for the data can be expensive, time-consuming, or impossible. That's where active learning comes in. With active learning, the algorithm doesn't passively learn from the data provided. Instead, it has the ability to query a human operator for the label of specific instances that it believes will help it improve the most.\n",
    "\n",
    "Example<br>Let's say you're training a machine learning model to recognize cats in images. Instead of labeling thousands of images by hand, you might use active learning. You'd start by labeling a few images, and the model would learn from those. Then, the model would look at a set of unlabeled images and choose a few that it's not certain about. You'd label those, the model would learn some more, and the cycle would continue. Over time, the model would get better at recognizing cats and you'd need to do less labeling.\n",
    "\n",
    "### Semi-supervised Learning\n",
    "Semi-supervised learning is a machine learning paradigm where the model is trained using a combination of a small amount of labeled data and a large amount of unlabeled data. The idea is to use the unlabeled data to enhance the learning accuracy of the model trained on the small amount of labeled data.\n",
    "\n",
    "### Ensemble Learning\n",
    "Explained further. (4.8.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d889fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "954e24c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24f9e293",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "A neural network is a computational model inspired by biological neural networks that constitute brains. The term neural network is a reference to neurobiology, but although some of the central concepts in deep learning were developed in part by drawing inspiration from our understanding of the brain, deep-learning models are not models of the brain. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with task-specific rules.\n",
    "\n",
    "Neural networks can adapt to complex patterns and generate predictions from input data, making them widely useful for tasks such as image recognition, speech recognition, natural language processing, and anomaly detection in time series data.\n",
    "\n",
    "A neural network takes in inputs, which are then processed in hidden layers using weights that are adjusted during training. Then it gives an output, which is used to infer results. Each node in a layer is connected to nodes in the previous and next layer through 'edges', and these connections are associated with weights. Weights determine the contribution of inputs to a neuron‚Äôs output.\n",
    "\n",
    "## Layer\n",
    "Layers are composed of nodes through which data is processed. Each layer performs a certain computation on its input and passes the result to the next layer. The layers in a neural network are typically structured in a sequential manner, forming a pathway from the input to the output of the network. \n",
    "\n",
    "The layers are trained using the backpropagation algorithm and a gradient-based optimization method. The aim is to adjust the weights and biases of the neurons in a way that minimizes the difference between the network's output and the actual target value.\n",
    "\n",
    "### Input Layer\n",
    "The input layer receives the raw data from the dataset. It's essentially the entry point of the network, where each node corresponds to one feature in the data. Then mthe input layer passes it into the network, allowing it to be processed by the subsequent layers.<br>The number of nodes in the input layer usually corresponds to the number of features in your dataset.\n",
    "\n",
    "### Hidden Layers\n",
    "Hidden layers sit between the input and output layers and perform the bulk of the computation in the network. Each node in a hidden layer represents a learned feature, and the network learns these features during training. The \"depth\" of a neural network is determined by the number of hidden layers it contains. Each hidden layer transforms its input data into a more abstract representation that should be useful for the task at hand.<br>The number of nodes in the hidden layers is a hyperparameter of the model, meaning it's a configuration that you choose before training the model.\n",
    "\n",
    "### Output Layer\n",
    "The output layer is the final layer. It translates the complex feature representations learned by the hidden layers into final output values. The nature of the output layer depends on the specific task that the network is designed to perform. The function applied at the output layer of a neural network is called the activation function.\n",
    "+ For a binary classification problem, the output layer would usually have one neuron that outputs a probability score for the positive class.\n",
    "+ For a multi-class classification problem, the output layer would usually have as many neurons as there are classes, each outputting a probability score for the corresponding class.\n",
    "+ For a multi-label classification problem, the output layer would usually have as many neurons as there are classes, each outputting a probability that the corresponding class is present in the input.\n",
    "\n",
    "## Nodes/Neurons/Units\n",
    "A node or a neuron is a computational unit that makes up a layer. This is a mathematical function that takes one or more inputs, applies a set of weights to these inputs, sums them up, adds a bias term, and then passes the sum through an activation function then produces an output. The output of this activation function corresponds to the ouput of the layer. It is designed to mimic a neuron in a biological brain.\n",
    "\n",
    "Each node in a hidden layer or output layer has an associated bias term. This bias term allows the model to better fit the data by shifting the activation function to the left or the right, which can be crucial for successful learning.<br>Each connection between two nodes carries a weight. The weights are the primary components that are adjusted during the learning process. They determine the strength of the influence of one neuron on another. The input to a node is the sum of the weighted outputs from all neurons connected to it.\n",
    "\n",
    "Each node independently performs these bellow operations, and the outputs from all nodes in one layer become the inputs for the nodes in the next layer. The process continues layer by layer until it reaches the output layer, where the final prediction is made.\n",
    "\n",
    "### 1. Inputs\n",
    "Inputs are from either the original data (if it's in the input layer) or from neurons in the previous layer (if it's in a hidden layer or the output layer).\n",
    "\n",
    "### 2. Weighted sum (Weights and biases)\n",
    "Weighted sum is the combination of input features (x) and their associated weights (w). This weighted sum is then adjusted by a bias term (b) before being passed to the activation function.<br>\n",
    "Every nodes has an associated weight and bias, which represents its relative importance. These weights, along with a bias term, are the adjustable parameters from what the network adjusts to learn based on the error it made on its predictions during the training process. Weights control the strength of the connection between two neurons. A bias term is an extra input that is added to every node, it helps to fit the output from a node to the target values. Without a bias term, a neuron's output would always be 0 when all its inputs are 0, which could limit the model's ability to fit the data.<br>\n",
    "With that, the neuron computes a weighted sum of its inputs, which is the sum of each input multiplied by its corresponding weight, plus the bias term.\n",
    "\n",
    "Linear transformation:<br>y = wx + b\n",
    "+ \"x\" is the input data.\n",
    "+ \"w\" is the weight.\n",
    "+ \"wx\" is the weighted sum, which is the sum of each input (x) multiplied by its corresponding weight (w).\n",
    "+ \"b\" is the bias.\n",
    "+ \"y\" is the the output data.\n",
    "\n",
    "### 3. Activation Function\n",
    "Each node uses an activation function that is applied on the weighted sum. This function determines whether a neuron should be activated or not, based on the weighted sum of its input. The activation function is a mathematical function that transforms the weighted sum into an output that will be sent to the next layer. It introduces non-linear properties to the network's learning mechanism, enabling it to learn complex patterns.\n",
    "\n",
    "Activation functions are specified during the creation of a layer. For example, in layers.Dense(64, activation='relu'), a Dense layer is created with a ReLU activation function. \n",
    "\n",
    "#### Sigmoid Function\n",
    "This function maps the input values between 0 and 1. It is typically used in the output layer of a binary classification problem where we want an answer that corresponds to a probability between 0 and 1.\n",
    "\n",
    "#### Softmax Function\n",
    "The softmax function is often used in the output layer of a classifier where we're trying to attain the probabilities to define the class of an input.\n",
    "\n",
    "#### Tanh Function (Hyperbolic Tangent)\n",
    "This function maps the input values between -1 and 1.\n",
    "\n",
    "#### ReLU Function (Rectified Linear Unit)\n",
    "It computes the function as f(x) = max(0, x). In other words, the output is the input directly if it is positive, otherwise, it is zero. It has been found to greatly accelerate the convergence of stochastic gradient descent compared to the sigmoid and tanh functions.\n",
    "\n",
    "#### Leaky ReLU Function\n",
    "It is a variant of ReLU. Instead of being zero when x<0, a leaky ReLU allows a small, non-zero gradient when the unit is not active.\n",
    "\n",
    "#### etc...\n",
    "\n",
    "### 4. Output\n",
    "The output of the activation function is the final output of the neuron. This output is then passed on to the neurons in the next layer, or it is outputted as the final prediction of the network if the neuron is in the output layer.\n",
    "\n",
    "## Loss function / Cost function / Objective function\n",
    "This is a method of evaluating how well the output predictions match the target values. If predictions deviate too much from actual results, loss function would cough up a very large number. A loss function quantifies the difference between the true output and the model's predicted output. This difference is often referred to as the \"error.\"<br>The objective is to find parameters that minimize the loss function. The process of minimizing (or optimizing) the loss is typically done using iterative optimization algorithms like Gradient Descent. The loss function is a crucial part of the learning process, as it provides feedback to the learning algorithm, guiding it to adjust the model's internal parameters to improve its performance.\n",
    "\n",
    "There are various types of loss functions, and the choice of loss function depends on the problem being solved. The loss function you choose also affects the learning dynamics: how quickly or reliably your model learns and how prone it is to overfitting or underfitting.\n",
    "\n",
    "### Binary Cross-Entropy (Log Loss)\n",
    "This loss function is used in binary classification problems, where the task is to predict one of two classes. It measures the difference between the actual and predicted probabilities for the positive class.\n",
    "\n",
    "### Categorical Cross-Entropy\n",
    "This loss function is used in multi-class classification problems, where the task is to predict one of more than two classes. It measures the difference between the actual and predicted probabilities for each class.\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "This is the most common loss function for regression problems, where the task is to predict a continuous output. It measures the average squared difference between the actual and predicted values. The goal is to minimize this difference.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "This is another loss function for regression tasks. It measures the average absolute difference between the actual and predicted values.\n",
    "\n",
    "### Huber Loss\n",
    "This loss function is less sensitive to outliers in data than mean squared error. It combines properties of both MSE and MAE. For small errors, it is similar to MSE, while for larger errors, it is similar to MAE, thus providing a balance between the two.\n",
    "\n",
    "### etc...\n",
    "\n",
    "## Backpropagation (Backward pass / Backward propagation of errors)\n",
    "Backpropagation is the algorithm used to compute the gradient of the loss function with respect to the weights in the model, and does so efficiently, unlike a naive direct computation.\n",
    "\n",
    "The goal of backpropagation is to minimize the error or the difference between the actual and the predicted output. It is called \"backpropagation\" because once the output layer's errors are calculated, they are then propagated backward throughout the network, from the final layer to the input layer, allowing the weights to be updated. The ability to adjust the weights based on the error enables the model to \"learn\" from the data, improving its performance over time.\n",
    "\n",
    "Here's how it works\n",
    "1. Forward Propagation\n",
    "The input data is passed through the network, from the input layer to the output layer where a prediction is made.\n",
    "2. Loss Computation<br>The predicted output is compared to the true output using the loss function, and the loss function is computed.\n",
    "3. Calculate Gradients at the Output Layer<br>This is done by taking the derivative of the loss function with respect to the network's output, and multiplying it by the derivative of the output layer's activation function with respect to its inputs.\n",
    "3. Backpropagation the Error<br>For each layer, calculate the error for each neuron by taking the sum of the errors of all neurons in the next layer, each multiplied by the weight of the connection to that neuron, and then multiplying that by the derivative of the activation function for the current neuron.\n",
    "4. Calculate Gradients in Hidden Layers<br>The gradients for the weights and biases in each hidden layer are computed using the error just calculated for that layer and the inputs to that layer.\n",
    "5. Update Weights<br>These gradients are then used to update the parameters of the network in a way that minimizes the loss. This is typically done using an optimization algorithm like Gradient Descent or one of its variants.\n",
    "\n",
    "To summarize: After the loss Computation, starting from the output layer and moving backwards through each hidden layer having weight and bias, the backpropagation algorithm calculates the gradient of the loss function with respect to the weights and biases. Computing the gradient of the loss in each layer provides a measure of the \"amount of contribution\" to the error that helps us adjust the weights and biases to reduce the overall error. The gradients are calculated using the chain rule of differentiation, which allows the error to be 'backpropagated' to each layer. This provides a method for dividing the error among the neurons according to their contribution. When calculating gradient, we use an optimization algorithm to adjust the weights and biases in the direction that minimizes the loss.\n",
    "\n",
    "### Optimizer (update step)\n",
    "An optimizer is an algorithm used to adjust the attributes of your model such as weights and learning rate in order to reduce the losses. Optimizers help to get results faster. After the gradients have been calculated, the optimizer then uses these gradients to update the model's weights and biases in an attempt to minimize the loss function. This process is typically referred to as an optimization step or an update step.\n",
    "\n",
    "The gradient is a multi-dimensional concept that generalizes the derivative to functions of multiple variables. The gradient of a function is simply a vector that contains all of these partial derivatives. It points in the direction of the greatest rate of increase of the function.\n",
    "\n",
    "Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent.<br>While gradient descent is a very effective optimizer for many scenarios, it does have some drawbacks. It can get stuck in local minima in case of non-convex error surfaces, or can be slow to converge in some cases.\n",
    "\n",
    "There are several types of gradient descent algorithm, which differ in how much data we use to compute the gradient of the objective function.\n",
    "\n",
    "#### Batch Gradient Descent (BGD)\n",
    "This is the most basic type of optimizer. It uses the derivative of the loss function with respect to the parameters to find the direction to move in the parameter space to minimize the loss.\n",
    "\n",
    "#### Stochastic Gradient Descent (SGD)\n",
    "SGD calculates the gradient using a single random sample from the dataset that is used at each iteration of the algorithm. This is faster and can escape shallow local minima, but it also introduces a lot of variance in the learning process.\n",
    "\n",
    "#### Mini-Batch Gradient Descent\n",
    "A compromise between Batch Gradient Descent and Stochastic Gradient Descent. It uses a random subset of the dataset at each iteration of the algorithm.\n",
    "\n",
    "#### RMSProp (Root Mean Square Propagation)\n",
    "RMSProp is an adaptive learning rate method. It divides the learning rate by an exponentially decaying average of squared gradients. The main benefit of RMSProp over standard gradient descent is that it's able to change the learning rate adaptively for each weight in the model, which can be very beneficial when dealing with complex neural network models.\n",
    "\n",
    "#### Adam (Adaptive Moment Estimation)\n",
    "Adam is an optimization algorithm that can be seen as a combination of RMSProp and Momentum. It uses the concept of momentum by adding fractions of previous gradients to current ones (like Momentum). And, like RMSProp, it also uses the squared gradients to scale the learning rate. It stores an exponentially decaying average of past gradients (similar to momentum) and also keeps an exponentially decaying average of past squared gradients (like RMSProp).\n",
    "\n",
    "#### Momentum\n",
    "Momentum isn't an optimizer by itself, this is a method that helps accelerate gradients vectors in the right directions, leading to faster converging. It is inspired by the physical concept of momentum. It adds a fraction of the direction of the previous step to a current step. This serves to dampen oscillations and speed up the search for a minimum. The momentum term (usually denoted as Œ≥) is a hyperparameter set between 0 and 1.\n",
    "\n",
    "#### etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add1c04",
   "metadata": {},
   "source": [
    "# Layer types\n",
    "\n",
    "## Activation Layers\n",
    "An Activation Layer is a layer that applies an activation function to its input. It's important to note that \"activation function\" and \"activation layer\" aren't interchangeable. The activation function is the function that is applied, and the activation layer is the layer where this function is applied.\n",
    "\n",
    "For instance, the term \"ReLU layer\" is generally used to refer to a layer in which the ReLU function is applied to its inputs.\n",
    "\n",
    "+ layername_1D is used for convolution over sequences, for instance in time series analysis or natural language processing.\n",
    "+ layername_2D is used for images, where each convolutional filter looks at a patch of the image.\n",
    "+ layername_3D extends this concept into three dimensions and is used for volumetric data or video, where you might want to look at a 3D patch in space (height x width x depth) or a 3D patch in space-time (height x width x time).\n",
    "\n",
    "\n",
    "### ReLU Layer\n",
    "The ReLU layer applies a ReLU function that effectively removing any negative values in the feature maps and introducing non-linearity to the model. This is important because it allows the network to learn complex patterns and relationships in the data. Without a non-linear activation function, no matter how many layers the network has, it would still only be capable of learning linear relationships. Compared to other activation functions like sigmoid or tanh, ReLU is computationally efficient because it doesn't involve expensive operations (like exponentials). Furthermore, during backpropagation, derivative of the ReLU function is 1 for positive input and 0 for negative input. This means that during the training process, layers that use ReLU as an activation function are less likely to suffer from the vanishing gradient problem, which can hinder learning in deep networks.\n",
    "\n",
    "One issue is the called \"dying ReLU\" problem, where a large gradient update can cause a ReLU neuron to output 0 for all subsequent inputs. If this happens, the neuron is effectively dead and cannot contribute to learning anymore, since the gradient for this neuron will always be 0. Variants such as Leaky ReLU or Parametric ReLU have been proposed to alleviate this problem.\n",
    "\n",
    "## Dense Layers (FC layers) (fully connected layers)\n",
    "A Dense layer is a type of layer where each input node is connected to each output node, this is why it's called \"fully connected\" or \"dense\". This allows the network to learn complex patterns by combining the features learned in previous layers in various ways. Dense layers are often used in the final layer of a network, where the network makes its final decision about what it has learned from the input data\n",
    "\n",
    "They might not always be the best choice for every type of data or problem. Using it in image data might be inappropriate and inefficient. When processing image data, dense layers consider each pixel independently. In doing so, they fail to take into account the spatial relationships between the pixels, which are often crucial in image processing tasks. A dense layers applied to an image data will treat each pixel as a separate feature, ignoring any inherent spatial hierarchies present. This could lead the network to learn overly complex or potentially misleading patterns.\n",
    "\n",
    "Dense layer expects a single vector (one-dimensional array) for each instance in the batch. This is why you often see Flatten layers preceding Dense layers in network architectures, especially when dealing with multidimensional input data like images\n",
    "\n",
    "Example<br>\n",
    "Consider that you have a batch of 32 images, each of size 28x28 pixels (for a grayscale image). If you wanted to pass these images to a Dense layer, you wouldn't be able to feed the 28x28 images directly into it. Instead, you would have to flatten or reshape each 28x28 image into a one-dimensional vector of size 784 (28*28=784). Hence, instead of feeding the Dense layer a 3D array of shape (32, 28, 28) (representing a batch of 32 2D images), you'd feed it a 2D array of shape (32, 784) (representing a batch of 32 1D vectors). Each vector in the batch is an individual, flattened instance of your data.\n",
    "\n",
    "## Flatten Layer\n",
    "A Flatten layer transforms a multi-dimensional tensor into a one-dimensional tensor, also known as a vector. This transformation is often called 'flattening', hence the name 'Flatten layer'. The Flatten layer does not have any learnable parameters, i.e., during the training process, it does not learn or update any weights. Its only purpose is to change the dimensions of the input tensor. This is often necessary because certain types of layers (like Dense layers) expect their input in a certain shape (typically as a 1D vector), which might not match the shape of the output from the previous layer. In these cases, a Flatten layer is used to reshape the output from one layer into the appropriate shape for the next layer.\n",
    "\n",
    "## Pooling Layer ([Max, Average]Pooling[1, 2, 3]D\n",
    "The pooling layer is a form of non-linear down-sampling. It partitions the input image into a set of non-overlapping rectangles and, for each such sub-region, outputs the maximum (Max Pooling) or average (Average Pooling).<br>Pooling is an operation that is commonly added to Convolutional Neural Networks (CNNs) to reduce the spatial size (width and height) of the intermediate feature maps generated by convolutional layers. This reduction helps to decrease the computational complexity of the network, as well as control overfitting.\n",
    "\n",
    "### Global Average Pooling (GAP)\n",
    "Global Average Pooling is a pooling layer that calculates the average value for each feature map in the previous layer. Unlike traditional pooling layers, such as max pooling or average pooling, which have a kernel size and stride that allow them to slide over the feature maps and pool over a local region, GAP pools over the entire spatial dimension of a feature map. If you have a feature map of shape (height, width, channels), GAP will calculate the average value across the height and width for each channel, resulting in an output of shape (1, 1, channels) This operation condenses each feature map into a single value, effectively summarizing the spatial information. By averaging over the entire spatial dimension, GAP captures the global context of the feature maps. This can be useful in tasks such as image classification, where global information about the presence of particular features or patterns is more important than their specific locations. Since GAP operates on the entire spatial dimension, it allows the model to handle inputs of varying sizes without modification.\n",
    "\n",
    "## Convolutional layers (Conv[1, 2, 3]D)\n",
    "Convolutional layers are one of the main building blocks of Convolutional Neural Networks (CNNs), which are primarily used for tasks related to image processing, but can also be used for other types of sequential data. They are inspired by the visual cortex of animals, where it has been observed that only a small region of the visual field activates individual neurons. This concept is replicated in convolutional layers by applying a series of filters to an input, which could be an image or the output from a previous layer.\n",
    "+ Convolution step (local receptive fields)<br>A small region (e.g. 3x3 or 5x5 pixels) in the input image is connected to a neuron in the output layer. This region is then moved across the entire image to create the full output.\n",
    "+ Shared weights and biases<br>Each neuron in the output layer uses the same weight and bias values. This greatly reduces the number of parameters in the model, making it easier to train and less prone to overfitting.\n",
    "+ Activation maps / feature map<br>The output of a convolutional layer is called an activation map or feature map. It represents the features that the layer has learned to recognize. Early layers in a CNN might learn to recognize simple shapes, colors or edges, while deeper layers learn more abstract concepts built up from the features recognized by the previous layers.\n",
    "+ Multiple filters<br>A convolutional layer will have many different filters, each producing a separate output channel. Each filter will learn to recognize a different feature in the input data.\n",
    "\n",
    "## Dropout layer\n",
    "Dropout is only active during the training phase (learning were computed with dropout). During the testing phase, when the model is used to make predictions on unseen data, dropout is turned off and the weights are scaled down by a factor equal to the dropout rate, to balance the fact that more neurons are active than during training. Dropout introduces randomness into the model during training because it randomly sets a certain fraction of inputs to zero. During testing, we want our model to be deterministic, meaning the same input should always produce the same output. If dropout were active during testing, it could lead to inconsistent results because different neurons might be \"dropped out\" each time the same input is fed into the network, resulting in potentially different outputs for the same input. Dropout also has a regularization effect, reducing the chance of overfitting. By randomly dropping out neurons, it becomes harder for the model to memorize the training data. This helps to prevent overfitting to the training data and can result in better generalization to new, unseen data. Dropout reduce the total computation time because it effectively reduces the number of neurons, which speed up the training process.\n",
    "\n",
    "Dropout has been found to be very effective for a wide range of tasks specially for large datasets that contain noise, but it's not the best tool for every job.\n",
    "It can hurt performance for \n",
    "+ Small Datasets<br>If your dataset is relatively small, dropout might lead to underfitting. This is because dropout regularizes the model, and with a small dataset, there isn't as much of a risk of overfitting in the first place.\n",
    "+ Converging Too Slowly<br>Dropout can slow down the convergence of the model training because it adds randomness into the training process. If speed of training is a concern, dropout might not be the best choice.\n",
    "+ Complex Models With Many Layers<br>Dropout could cause problems if used with complex architectures that already have other regularization techniques in place. For instance, using dropout with Batch Normalization needs careful consideration as they both normalize layer's inputs and could interfere with each other. Furthermore, some modern architectures like ResNet use skip connections which themselves act as a form of regularization.\n",
    "+ Wrong Dropout Rate<br> If the dropout rate is too low, it may not provide enough regularization to have a noticeable impact. On the other hand, if the dropout rate is too high, it might lead to underfitting because too much information is being lost at each layer.\n",
    "\n",
    "Applying a dropout layer right after a Convolutional layers is not always the best strategy because the Convolutional layers are responsible for learning the spatial hierarchies and applying the Dropout layer immediately after might disrupt this process.\n",
    "\n",
    "As a general rule, dropout is a powerful regularization technique, but it's not always the case that more dropout is better. The correct amount of dropout depends on the specific network architecture, the dataset, and the complexity of the problem. Too much dropout can lead to underfitting, as the model becomes too regularized to learn from the data. Applying dropout after every layer can cause the model to lose useful information. You're adding a lot of noise into the process and might be dropping out too much useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c0dab",
   "metadata": {},
   "source": [
    "# Learning dynamics\n",
    "\n",
    "## Learning\n",
    "Learning describes an automatic search process for better representations. All machine-learning algorithms consist of automatically finding such transformations that turn data into more-useful representations for a given task. When it's working, the model learns.\n",
    "\n",
    "## Hypothesis space\n",
    "Hypothesis space defines the set of all possible functions/transformations/models that the learning algorithm could select as its solution. The set is able to turn data into more-useful representations that the algorithm can learn from the data. Essentially, it is the space of all possible relationships the model can capture between the inputs and the output. The choice of hypothesis space has a significant impact on the learning process and the quality of the resulting model.\n",
    "\n",
    "All machine-learning algorithms consist of automatically finding such transformations that turn data into more-useful representations for a given task. Coordinate changes, linear projections, translations and so on. A small hypothesis space may lead to underfitting, where the model is too simple to capture the underlying patterns in the data. On the other hand, an excessively large hypothesis space can lead to overfitting, where the model fits the training data too closely but fails to generalize well to unseen data.\n",
    "\n",
    "## Underfitting\n",
    "Underfitting refers to a learning situation where a model fails to capture the underlying patterns and relationships in the data. It occurs when a model is too simple or lacks the capacity to represent the complexity of the data. As a result, the model's performance is poor, both on the training set and on unseen data.\n",
    "\n",
    "Underfitting can be addressed by increasing the model's complexity or capacity. This can involve using a more sophisticated model, adding more layers, increasing the number of parameters, or using more advanced techniques like ensemble methods. Additionally, gathering more relevant training data or applying data augmentation techniques can also help mitigate underfitting.\n",
    "\n",
    "## Overfitting\n",
    "Overfitting refers to a learning situation where a model learns the training data too well, to the extent that it memorizes noise or random fluctuations in the data instead of generalizing the underlying patterns. The model performs exceptionally well on the training data but fails to generalize effectively to unseen or test data.\n",
    "\n",
    "When a model overfits, it starts to \"memorize\" the training examples, including their idiosyncrasies and noise. This leads to poor performance on new data because the model has not learned the true underlying patterns but rather the specific examples it was trained on.\n",
    "\n",
    "## Convergence\n",
    "Convergence refers to the point at which further training on the data does not significantly improve the model's performance. The model's performance has \"converged\" to a minimum value.\n",
    "\n",
    "## Gradient Problems\n",
    "\n",
    "### Vanishing Gradient\n",
    "The vanishing gradient problem is a difficulty found with gradient-based learning methods and backpropagation. The problem becomes significant when dealing with many layers of function compositions. During the backpropagation process, the gradients of the loss function can become very small as they are backpropagated through layers of the network. As a result, the weights in the earlier layers of the network are updated to a much smaller degree than those in the later layers. This is problematic because it makes the network hard to train effectively: the earlier layers train very slowly, or may stop training altogether, causing the network as a whole to fail to converge or to converge to a suboptimal solution.\n",
    "\n",
    "This issue is caused by the nature of the activation functions used in these networks. Traditional activation functions such as the sigmoid or the hyperbolic tangent function squish a large input space into a small range between 0 and 1, or -1 and 1 respectively. When these activation functions are applied repeatedly through many layers, the gradients can be squished until they effectively vanish and cause learning to either become very slow or completely stop.\n",
    "\n",
    "The advent of techniques like better weight initialization, batch normalization, and advanced activation functions like ReLU that help mitigate this problem.\n",
    "\n",
    "### Exploding Gradient\n",
    "Same as vanishing gradient, exploding gradient is related to the magnitude of the gradients, but in the opposite direction. This usually happens when the weights in a network are too large. Because the gradients are used to update the weights in the network, large gradients cause large changes in the weights, which can result in an unstable and chaotic network that is unable to learn from the data.\n",
    "\n",
    "This issue can be mitigated using various techniques such as gradient clipping, where an upper limit is placed on the magnitude of the gradient. Other solutions involve careful initialization of the network's weights, use of activation functions that don't saturate (like ReLU), or employing more advanced weight optimization methods.\n",
    "\n",
    "LSTMs and GRUs were specifically designed to tackle these gradient-related problems in RNNs where the problem is particularly troublesome.\n",
    "\n",
    "## Hyperparameters\n",
    "Hyperparameters are the parameters whose values are set prior to the commencement of the learning process. They are not learned from the data but are often tuned manually, based on understanding of the task and model at hand, or using some form of automated hyperparameter optimization, such as grid search or random search.\n",
    "\n",
    "### Learning Rate\n",
    "This is one of the most important hyperparameters in many optimization algorithms, such as gradient descent. It controls how much the model's parameters are updated in response to the estimated error each time the model's weights are updated. It determines the step size when moving towards a minimum of the loss function. Too small a learning rate can result in slow convergence, while too large a learning rate can cause the model to diverge.\n",
    "\n",
    "### Batch (Batch Size)\n",
    "A batch refers to a subset of the entire training dataset that are propagated through the network in one iteration. The batch size defines the number of samples to work through before updating the internal model parameters.<br>Larger batch sizes can lead to faster training, but the gradient estimates may be less accurate. A smaller batch size usually means more updates in a given epoch, which can provide a more accurate estimate of the gradient. However, smaller batch sizes are also noisier, and the model may not converge as fast. Conversely, larger batch sizes yield less noisy estimation of the gradient, but also less frequent updates, which slows down the learning process.\n",
    "\n",
    "### Epochs\n",
    "An epoch is one complete pass through the entire training dataset. During an epoch, the model's weights are updated to minimize the loss function. After that the dataset has been divided into batches, each batch of data is passed through the model, for each batch of the backpropagation is happening. When an epoch ends, the model's performance is evaluated on the validation data.\n",
    "\n",
    "### Number of Layers\n",
    "This determines the depth of the neural network. Deeper networks (i.e., networks with more layers) can represent more complex functions, but they are also more prone to overfitting and are harder to optimize.\n",
    "\n",
    "### Number of Units per Layer\n",
    "This is also known as the layer width. Similar to the number of layers, having more units can allow the network to represent more complex functions, but it also makes the network more prone to overfitting and harder to optimize.\n",
    "\n",
    "### Weight Initialization\n",
    "The way the weights in the network are initialized can have a big impact on the final performance of the network. There are various strategies to initialize the weights, like zero initialization, random initialization, and Xavier/Glorot or He initialization.\n",
    "\n",
    "### Activation Function\n",
    "This function is applied at each node in a layer and determines the output of that node given an input or set of inputs. Examples include the sigmoid, tanh, and ReLU functions.\n",
    "\n",
    "### Optimizer\n",
    "The choice of optimization algorithm can have a significant impact on the speed and quality of learning, such as SGD (Stochastic Gradient Descent), Adam, RMSProp, etc.\n",
    "\n",
    "### Loss Function\n",
    "This function measures the inconsistency between the predicted and actual labels. Common choices include mean squared error, cross-entropy loss, etc.\n",
    "\n",
    "### Regularization Techniques (Regularization Parameters)\n",
    "Regularization techniques are generally considered a type of hyperparameter that needs to be configured for training a machine learning model. Regularization is a process of introducing additional information or constraints into a model to prevent overfitting and improve the model's generalization. It helps to ensure that the model generalizes well from the training data to unseen data.\n",
    "\n",
    "It is quite common in practice to combine several regularization techniques at the same time. When combining different regularization techniques, it's important to tune the amount of regularization applied by each technique. Too much regularization can cause underfitting, while too little can cause overfitting. This tuning is typically done through cross-validation.\n",
    "\n",
    "#### L1 and L2 regularization\n",
    "L1 and L2 are the most common types of regularization. They work by adding a penalty to the different parameters of the machine learning model to reduce the freedom of the model and in turn minimize overfitting.\n",
    "\n",
    "+ L1 Regularization (Lasso regularization)<br>Introduces a penalty term that is the absolute value of the magnitude of the coefficients. It tends to produce sparse solutions, with many parameters being zero, effectively reducing the number of features upon which the given solution is dependent.\n",
    "\n",
    "+ L2 Regularization (Ridge regularization)<br>Introduces a penalty term that is the square of the magnitude of the coefficients. Unlike L1 regularization, L2 regularization will not result in sparse solutions and does not reduce the number of features. Instead, it limits the influence of each feature, which can be beneficial in multi-collinearity situations.\n",
    "\n",
    "#### Dropout\n",
    "Dropout is a regularization technique that reduces the complexity of a model. It works by randomly \"dropping out\" (temporarily removing) a number of output features of the layer during the training phase. This is a technique where randomly selected neurons are ignored during training, meaning that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass. Dropout has the effect of making the training process noisy, forcing nodes within a layer to probabilistically take on more or less responsibility for the inputs. This forces the remaining neurons to learn more robust features that are useful in conjunction with many different random subsets of the other neurons.<br>\n",
    "The \"dropout rate\" is the fraction of the features that are zeroed out. A dropout rate of 0.5 means approximately 50% of output features are zeroed out.\n",
    "\n",
    "#### Early stopping\n",
    "During the training process, the model is evaluated on a holdout validation dataset after each epoch. If the performance of the model on the validation dataset starts to degrade (loss begins to increase or accuracy begins to decrease), then the training process is stopped. By stopping the training when the validation loss starts to increase, early stopping prevents the model from learning the noise in the training set and therefore from overfitting to the training data.\n",
    "\n",
    "#### Data Augmentation\n",
    "Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks to increase the diversity and size of the training set, without actually collecting new data. This technique adds slight variations in the training data, without changing their labels, thus providing a more generalized way of learning the patterns. Sometimes, a too aggressive augmentation can result in overly distorted images that might confuse the model instead of helping it.\n",
    "\n",
    "#### Batch Normalization\n",
    "Batch Normalization is a method used to make artificial neural networks faster and more stable. It normalizes the activations of the neurons in the network across each batch. For each mini-batch, it computes the mean and variance of that mini-batch, then subtracts the mean and divides by the standard deviation (resulting from the variance), effectively normalizing the batch's activations to have zero mean and unit variance. Then, the process applies a learned scale factor and shift.\n",
    "\n",
    "It allows each layer of a network to learn more independently of the other layers, which can speed up learning and has a regularizing effect, reducing the need for other regularization methods like dropout. This is because the normalization adds a small amount of noise to the network. When applied to the last layer of a network, it can allow for the use of higher learning rates, potentially providing a speed boost in network training.\n",
    "\n",
    "It's not always the best choice. It adds complexity to the model, can cause a computational overhead, and might not be as beneficial for smaller networks or those with little training data.\n",
    "\n",
    "Batch Normalization is usually applied before the activation function of a layer. It can be directly incorporated into network architectures in frameworks like TensorFlow and Keras using the BatchNormalization layer.\n",
    "\n",
    "#### Noise Injection\n",
    "Noise injection is a simple concept where we add a little bit of noise to the input data or inside the model, in the hope that it will make the model more robust and prevent overfitting.\n",
    "\n",
    "For instance, a Gaussian noise (also knowned as white noise) can be added to the input data. Gaussian noise is added to the data by generating random numbers that follow a Gaussian distribution. The mean of this distribution is usually 0, and its standard deviation determines the spread or \"noisiness\" of the noise. When Gaussian noise is added to the data, each input feature will be perturbed by a different amount of noise, making the model's task slightly harder and hopefully encouraging it to learn more robust, generalizable patterns in the data. It's important to note that the noise is only added during training, not during evaluation or testing.\n",
    "\n",
    "### Momentum\n",
    "Often used as a part of the optimization algorithm, momentum helps accelerate gradient descent in the relevant direction and dampens oscillations.\n",
    "\n",
    "## Model Evaluation\n",
    "Model Evaluation are all essential techniques and metrics used for assessing machine learning model performance. These techniques will provide a comprehensive view of how well our models generalize and perform on unseen data.\n",
    "\n",
    "### Evaluation Metrics\n",
    "Evaluation metrics are used to measure the quality of a prediction. They quantify the performance of a model on test data that it has never seen before, after being trained on training data. Choosing the correct evaluation metric is a crucial step in machine learning as it helps you understand the performance of your model.\n",
    "\n",
    "#### Classification Metrics\n",
    "+ Accuracy<br>This is the most intuitive metric. It is a ratio of correctly predicted observations to the total observations.<br>Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)\n",
    "+ Precision<br>Precision is the ratio of correctly predicted positive observations to the total predicted positive observations.<br>Precision = TP / (TP + FP), TP is the number of true positives and FP is the number of false positives.\n",
    "+ Recall (Sensitivity)<br>Recall is the ratio of correctly predicted positive observations to all actual positives.<br>Recall = TP / (TP + FN), FN is the number of false negatives.\n",
    "+ F1 Score<br>The F1 score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.<br>F1_Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "+ ROC Curve (AUC-ROC)<br>The Receiver Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity. The area under the ROC curve (AUC) is the measure of the ability of a classifier to distinguish between classes.\n",
    "\n",
    "#### Regression Metrics\n",
    "+ Mean Absolute Error (MAE)<br>The average of the absolute differences between predictions and actual values. This metric gives an idea of how wrong the predictions were.<br>MAE = (1/n) * Œ£|y - ≈∑|, y is the actual value, ≈∑ is the predicted value, and n is the number of samples.\n",
    "+ Mean Squared Error (MSE)<br>The average of the squares of the differences between the predicted and actual values. This metric is popular because it punishes larger errors, which tends to be useful in the real world.<br>MSE = (1/n) * Œ£(y - ≈∑)¬≤\n",
    "+ Root Mean Squared Error (RMSE)<br>This is the square root of the mean of the squared errors.<br>RMSE = ‚àö[(1/n) * Œ£(y - ≈∑)¬≤]\n",
    "+ R-squared<br>It represents how close the data are to the fitted regression line. The higher the R-squared, the better the model fits your data.<br>R¬≤ = 1 - (SSR / SST), SSR is the sum of squares of residuals and SST is the total sum of squares.\n",
    "\n",
    "### Bias-Variance Tradeoff\n",
    "The bias-variance tradeoff describes the tension between model complexity and model generalization. This is the balance that must be achieved between bias (underfitting) and variance (overfitting) in order to minimize the total error.\n",
    "\n",
    "Bias can be thought of as the difference between the average prediction of our model and the correct value we are trying to predict. High bias can cause an algorithm to miss relevant relations between features and target outputs (underfitting).\n",
    "\n",
    "Variance refers to the amount that our model estimate would change if we estimated it using a different training dataset. High variance can cause overfitting.\n",
    "\n",
    "The tradeoff between bias and variance can be visualized as a U-shaped curve, where total error is minimized when there is a right balance of bias and variance. If a model is too simple, it may have high bias (underfitting). If a model is too complex, it may have high variance (overfitting). The optimal balance is a model that has both low bias and low variance, capturing the underlying patterns in data without being overly influenced by the noise or outliers.\n",
    "\n",
    "In practice, however, achieving this optimal balance can be challenging and may require techniques such as regularization, cross-validation, and ensemble methods.\n",
    "\n",
    "#### Regularization\n",
    "Use of regularization techniques are used to prevent overfitting by adding an additional penalty to the loss function.\n",
    "\n",
    "#### Cross-Validation\n",
    "Cross-validation is a technique for assessing how well the machine learning model is likely to perform on unseen data. The main idea is to hold out part of the available data as a test set. The model is trained on the larger part, and then the model's predictive performance is assessed using the held-out test set. The result is often given as the average of the model skill measure (like accuracy) and provides a better estimate of how well the model has been trained than traditional train/test split.\n",
    "\n",
    "##### K-fold\n",
    "This is the most cross-validation common technique and the one usually referred to if not specified. The original sample is randomly partitioned into k equal sized subsets, and the holdout method is repeated k times. Each time, one of the k subsets is used as the test set, and the other k-1 subsets are put together to form a training set. Then the average error across all k trials is computed.\n",
    "\n",
    "##### Leave One Out Cross Validation (LOOCV)\n",
    "This is a variation of k-fold where k equals the total number of observations in the data. In this method, the model is trained on all the data but one point and that point is used as a test set. This is repeated for all points in the dataset. It is computationally expensive given the number of times the training process is done.\n",
    "\n",
    "##### Stratified K-Fold Cross Validation\n",
    "This is a variation of k-fold which can create a biased model if the dataset is not equally balanced. For example, in a binary classification problem where each class comprises 50% of the data, it is best to arrange the data such that in every fold, each class comprises around half the instances.\n",
    "\n",
    "##### Time-Series Cross-Validation.\n",
    "This is a variation of k-fold which is used when data is collected over time. In this case, we have to respect the time in which data was collected and can't randomly shuffle the data as it can cause leakage. Hence, a variant of k-fold cross-validation is used where instead of randomly selecting the validation set, we respect the time in which the data was collected.\n",
    "\n",
    "##### etc...\n",
    "\n",
    "### Ensemble Methods (Ensemble Learning)\n",
    "Ensemble methods or ensemble learning are techniques that create multiple models and then combine them to produce improved results. Ensemble methods usually produces more accurate solutions than a single model would. This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods.\n",
    "\n",
    "#### Bagging\n",
    "Bagging tries to implement similar learners on small sample populations and then takes a mean of all the predictions. In generalized bagging, you can use different learners on different population. As you expect, it helps to reduce the variance error.\n",
    "\n",
    "#### Boosting\n",
    "Boosting is an iterative technique which adjust the weight of an observation based on the last classification. If an observation was classified incorrectly, it tries to increase the weight of this observation and vice versa. Boosting in general decreases the bias error and builds strong predictive models. However, they might overfit on the training data.\n",
    " \n",
    "#### Stacking\n",
    "Stacking is an ensemble learning technique that combines multiple classification or regression models via a meta-classifier or a meta-regressor. The base level models are trained based on complete training set then the meta-model is trained on the outputs of the base level model as features.\n",
    "\n",
    "## Model tuning\n",
    "Tuning the architecture of a deep learning model is more of an art than a science, and it generally requires a fair amount of experimentation to find the right balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616d8b55",
   "metadata": {},
   "source": [
    "# Architecture models\n",
    "There exist several different architecture models used in machine learning. Hybrid models are quite common and can be very effective for various tasks.\n",
    "\n",
    "## Fundamentals\n",
    "\n",
    "###  Perceptron (P-layer)\n",
    "The Perceptron is one of the simplest types of artificial neural networks and a foundation for more complex networks, it contains only one layer. Perceptron represents a binary linear classifier that maps its input x (a real-valued vector) to an output value f(x) (a single binary value) using a linear prediction function that combines a set of weights with the feature vector. The output is typically a binary decision: \"yes\" (1) or \"no\" (0).\n",
    "\n",
    "###  Multilayer Perceptron (MLP)\n",
    "An MLP consists of at least three layers of nodes. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. This distinguishes MLPs from a linear perceptron, as it can distinguish data that is not linearly separable, or separable by a hyperplane in its feature space.\n",
    "\n",
    "### Deep Neural Networks (DNNs)\n",
    "A model of deep learning, The term \"Deep\" refers to the number of layers in the network, implying that the network has more than just one or two layers. How many layers contribute to a model of the data is called the depth of the model.\n",
    "\n",
    "Training a Deep Neural Network involves using an algorithm such as Stochastic Gradient Descent, Adam, or RMSprop, among others. These algorithms adjust the parameters of the network to minimize a loss function. Backpropagation is also an algorithm frequently used in conjunction with these optimizers to effectively distribute error corrections from the output layer back through the hidden layers.\n",
    "\n",
    "### Feedforward Neural Networks (FNNs)\n",
    "Information in these networks travels only in one direction: from input to output. There are no loops in the network.\n",
    "\n",
    "## Convolutional Architectures\n",
    "\n",
    "#### Filters\n",
    "Convolutional architectures are mainly known for their use in image recognition and are currently state-of-the-art in various visual recognition tasks. Instead of using neurons they use filers. Filters are small parametable size (often 3x3) learnable matrices of weights. Each filter is convolved (a mathematical operation) across the width and height of the input volume, computing dot products between the entries of the filter and the input and producing an activation map that gives the responses of that filter at every spatial position.\n",
    "\n",
    "If you specify 32 filters for a convolutional layer, the layer will learn 32 different filters, each producing a distinct activation map. These 32 activation maps constitute the output volume of the layer.\n",
    "\n",
    "You can think of each filter in a convolutional layer as somewhat analogous to a neuron in a dense layer: it learns a pattern, and it activates when it sees that pattern. But that a single filter is responsible for detecting its pattern everywhere in the input, not just at one place, which is a key distinction.\n",
    "\n",
    "### Convolutional Neural Networks (ConvNets) (CNNs)\n",
    "ConvNets were inspired by the biological processes in the human brain, and particularly by the organization of the animal visual cortex. They are designed to automatically and adaptively learn spatial hierarchies of features.\n",
    "\n",
    "The key components of a ConvNets are\n",
    "+ Convolutional Layer<br>The first layer in a ConvNet is always a Convolutional Layer. The Convolutional Layer applies a set of learnable filters to the input. Each filter is small spatially (along width and height), but extends through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input, producing a 2-dimensional activation map for each filter. The resulting activation maps are stacked together along the depth dimension to produce the output volume.\n",
    "+ ReLU\n",
    "+ Pooling Layer\n",
    "+ Dense Layer\n",
    "\n",
    "They learn to extract increasingly complex features with each added layer, with earlier layers learning to detect simple patterns (like edges and colors) and deeper layers learning to recognize more complex features (like shapes or objects).\n",
    "\n",
    "### Residual Network (ResNet)\n",
    "ResNets are a type of deep neural network that have been particularly effective in practice. The key innovation in ResNets is the introduction of \"skip connections\" or \"residual connections\", which allow the network to learn an identity function and mitigate the problem of vanishing gradients, thus helping the network to train more effectively.\n",
    "\n",
    "#### Residual connections (skip connections) (shortcut connection)\n",
    "A residual connection refers to the technique of feeding the output from one layer to a later layer, skipping one or more layers in between. In this way, the network is learning the residual representation (the difference) between the input and output of the bypassed layers. These connections make it easier for the network to learn an identity mapping between layers where input and output are similar.\n",
    "\n",
    "The idea behind residual connections is to help combat the problem of vanishing gradients, it allows the gradients to propagate directly through several layers by providing a path that bypasses one or more transformation layers. This is most commonly used in deep convolutional neural networks (CNNs)\n",
    "\n",
    "## Recurrent Architectures\n",
    "\n",
    "### Recurrent Neural Networks (RNNs)\n",
    "These are used for sequential data tasks, like time series prediction, natural language processing (NLP), and speech recognition. They have loops that allow information to be carried across neurons along a sequence.\n",
    "\n",
    "### Long Short-Term Memory Networks (LSTMs)\n",
    "These are a special type of RNN designed to avoid the vanishing gradient problem, making them more effective at learning from longer sequences.\n",
    "\n",
    "### Sequence-to-Sequence (Seq2Seq)\n",
    "Seq2Seq models are a type of model architecture used NLP. Seq2Seq models are used to convert sequences from one domain (like English) to sequences in another domain (like the same sentences translated to French). Seq2Seq models are used in a variety of applications, including machine translation, speech recognition, and text summarization. While quite powerful, these models do have some limitations, such as difficulty handling very long sequences due to the information bottleneck created by compressing the entire input sequence into a single context vector. To address these limitations, enhancements such as attention mechanisms are often used in conjunction with Seq2Seq models.\n",
    "\n",
    "+ Encoder<br>The encoder processes the input sequence and compresses the information into a context vector, also sometimes called a \"thought vector\". This vector is a summary of the entire input sequence, and it's used as the initial hidden state of the decoder. The encoder is typically a RNN, such as a LSTM or a GRU.\n",
    "+ Decoder<br>The decoder takes the context vector generated by the encoder and generates the output sequence. Like the encoder, the decoder is often an RNN. It generates the output sequence step by step, using its previous predictions as input for the next step.\n",
    "\n",
    "## Generative Models\n",
    "\n",
    "### Autoencoder (AEs)\n",
    "Autoencoders are a special type of RNN designed to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation for a set of data, typically for dimensionality reduction or feature extraction. The model is trained by minimizing the difference between the input and the output, often using a loss function like mean squared error. One of the main use-cases of autoencoders is in the field of anomaly detection.\n",
    "+ Since autoencoders are good at learning the underlying structure of the input data, they can be used to detect anomalies by observing when the reconstruction error is high.\n",
    "+ Autoencoders is also used in dimensionality reduction. An autoencoder can be trained to compress data into a lower-dimensional space and then reconstruct the original data. This lower-dimensional space can be used as a representation of the original data for further tasks\n",
    "\n",
    "### Generative Adversarial Networks (GANs)\n",
    "GANs are nown for their ability to generate new, previously unseen data that resemble the distribution of the training data.\n",
    "\n",
    "## Transformer Networks (attention mechanisms)\n",
    "Transformers are primarily used in the field of NLP. They were introduced in a paper called \"Attention is All You Need\" by Vaswani et al., published in 2017. Transformers revolutionized NLP tasks by introducing a novel mechanism called the \"attention mechanism\". Attention allows the model to focus on different parts of the input sequence when predicting each part of the output sequence, instead of relying on a single context vector. This allows for better handling of long sequences and improves the model's performance on tasks like machine translation.\n",
    "\n",
    "The transformer architecture is composed of a stack of identical layers, each having two main parts: a multi-head self-attention mechanism, and a position-wise fully connected feed-forward network. A residual connection is employed around each of the two sub-layers, followed by layer normalization.\n",
    "\n",
    "### BERT (Bidirectional Encoder Representations from Transformers)\n",
    "BERT is a transformer-based machine learning technique for NLP pre-training developed by Google. BERT is deeply bidirectional, meaning it uses both left and right contexts in all layers of the model while previous models were largely unidirectional. This allows BERT to understand the context and ambiguity of words in a sentence, making it incredibly powerful for a wide range of NLP tasks.\n",
    "\n",
    "BERT is pre-trained on a large corpus of text (like the entire English Wikipedia), then fine-tuned for specific tasks.\n",
    "+ Pre-training is unsupervised and uses two tasks, \"masked language model\" and \"next sentence prediction\"\n",
    "+ Fine-tuning is supervised and tailored towards specific tasks like question answering, named entity recognition, or sentiment analysis.\n",
    "\n",
    "### GPT (Generative Pretrained Transformer)\n",
    "GPT is a type of transformer-based language model developed by OpenAI. The primary idea behind GPT is to use unsupervised learning to pre-train a large neural network on a diverse range of internet text. Then, this pre-trained model can be fine-tuned on specific tasks to achieve high performance with minimal task-specific adjustments. GPT is an autoregressive model, which means it produces outputs one part at a time, and the output at each time step is conditioned on the previous outputs. Unlike BERT, which uses both left and right context for predictions, GPT only uses left context (previous words in this case) to predict the next word.\n",
    "\n",
    "## Other Architectures\n",
    "\n",
    "###  Multi-Stream Network (Multi-Input)\n",
    "These architectures are commonly used in situations where you have different types of input data that need to be processed separately before being combined later in the network. Each branch of the network would be tailored to process its specific type of data. The outputs of these branches would then be combined in some way - either concatenated together, added, or even fed into another network - to produce a final prediction. This allows the model to learn from a variety of data types, each processed in a way that's appropriate for that type of data.\n",
    "\n",
    "### Graph Neural Network (GNN)\n",
    "These types of models are used when the input data forms a graph structure or when the architecture itself is best represented as a graph.\n",
    "\n",
    "### etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ce89c",
   "metadata": {},
   "source": [
    "# Data representation\n",
    "Data representation is the method used to present your data to a machine learning model. An effective data representation can streamline models and enhance their accuracy. The process involves multiple stages, such as data acquisition, preprocessing, transformation, and input into the model. The nature of your data should guide your choice of representation method. Inappropriate representation can impose an irrelevant order or overlook an inherent one, potentially diminishing model performance.\n",
    "\n",
    "## Type of data\n",
    "\n",
    "### Scalar\n",
    "A scalar is a single numerical value, typically a real number, that is used to measure a quantity. For example, temperature, speed, time, weight are all quantities that can be represented by scalars.\n",
    "\n",
    "### Vector\n",
    "A vector represent a set of features. Consider a dataset where we have three features: red, green, and blue. A single instance in this dataset could be represented as a 3-dimensional vector, such as (25, 170, 70).\n",
    "\n",
    "### Matrice\n",
    "A matrix is a two-dimensional array of numbers arranged in rows and columns. Each number in the matrix represents a certain feature of a data point. A vector can refer to either a row vector or a column vector.\n",
    "\n",
    "### Tensor\n",
    "A tensor is a specific type of mathematical object that is a generalization of scalars, vectors, and matrices. Tensors have properties that allow them to handle multi-dimensional problems and maintain these properties under changes in coordinate systems.\n",
    "\n",
    "Tensors are multi-dimensional arrays of numerical values. Each layer transforms the input tensor into an output tensor using a combination of linear and non-linear functions.<br>Tensors are a generalization of scalars, vectors, and matrices to higher dimensions (xD tensors).\n",
    "+ A scalar is a single number. It's a tensor of rank 0 (0D tensors).\n",
    "+ A vector is a one-dimensional array of numbers. It's a tensor of rank 1 (1D tensors).\n",
    "+ A matrix is a two-dimensional array of numbers. It's a tensor of rank 2 (2D tensors).\n",
    "+ for tensors of rank 3 and higher, there are no specific names. They are typically referred to just as tensors, often with their rank specified. (xD tensors).\n",
    "\n",
    "The features of your data set might initially be non-numerical types. However, these are usually converted to a numerical format that can be interpreted by a machine learning model in a process called feature encoding or feature transformation.\n",
    "This is because the computations involved in these models (such as addition, multiplication, dot products, etc.) are defined for numbers.\n",
    "\n",
    "In a tensor, an axis is a specific dimension along which data is organized. The number of axes in a tensor is also referred to as its rank. The 0 axis of a tensor, also known as the first dimension, is often called the \"batch\" axis or \"batch\" dimension when dealing with batches of data points. A 3D tensor has three axes, it can be: 0-depth, 1-height, 2-width\n",
    "\n",
    "Example<br>\n",
    "+ The tensor representing one colored image would have the shape (256, 256, 3). Each entry in the tensor is a pixel intensity, with the pixel at coordinate (i, j) in the color channel k given by the tensor entry (i, j, k).\n",
    "+ When working with multiple images, a 4D tensor is typically used. The dimensions represent (the number of images in the batch, colored image tensors). A batch of 32 RGB images each of size 256x256 would be represented as a tensor of shape (32, 256, 256, 3).\n",
    "+ Videos are typically represented as 5D tensors (batch size, image tensors) or (Number of videos in the batch, Number of frames in each video (time dimension), Height of each frame, Width of each frame, Color depth of each frame (channels).\n",
    "+ A tensor of the shape of (100, 50, 300) represents a batch of 100 samples where each sample is a sequence of 50 time steps and each time step has 300 features.\n",
    "\n",
    "Deep learning frameworks like TensorFlow and PyTorch are named after tensors because they utilize tensors in their fundamental operations.\n",
    "\n",
    "### Numerical Data\n",
    "This is quantitative data and involves numbers. Numerical data can be either continuous (height, weight) or discrete (number of children).<br>Examples: age, salary, temperature, ... \n",
    "\n",
    "### Categorical Data (qualitative data)\n",
    "This data involves values that can be divided/represented into multiple categories but having no order or priority.<br>In pandas there's a specific data type for categorical data: pandas.Categorical.<br>Examples: color (red, green, blue), city (New York, San Francisco), Unordered number representing class (1, 2, 3), ...\n",
    "\n",
    "### Ordinal Data\n",
    "This is similar to categorical data, but there's an order to the categories.<br>Example: rating scales (low, medium, high), education level (high school, bachelor's, master's, PhD), ...\n",
    "\n",
    "### Text Data\n",
    "Text data involves words, sentences, or even whole documents. It can be represented in many ways, such as bag-of-words, TF-IDF, word embeddings (like Word2Vec or GloVe), or sequence encodings (like one-hot encoding or integer encoding).\n",
    "\n",
    "### Time-Series Data\n",
    "Time series data is a type of data that is indexed by time. Time series data include daily stock prices, hourly weather measurements, or yearly population estimates. This data can have a temporal dependency that traditional statistical techniques may not be able to handle effectively.<br>RNNs and their more powerful variants LSTM units and GRUs, have proven to be very effective at processing time-series data. These models can learn patterns over time, making them well-suited for forecasting, anomaly detection, and other time-dependent tasks.\n",
    "\n",
    "### Image Data\n",
    "Image data is typically represented as three-dimensional arrays (height, width, and color channels). For grayscale images, it could be a two-dimensional array. The images are usually transformed into a numpy array containing numerical values representing the pixel intensities in different color channels.\n",
    "\n",
    "### Audio Data\n",
    "Audio signals are typically represented as time series data, which are sequences of sound amplitude measurements taken at uniform time intervals. Audio data is represented as one-dimensional tensors when it's in its raw waveform format. \n",
    "If you're working with mono audio, your tensor will be 1-dimensional. For stereo audio, your tensor will be 2-dimensional where the first dimension represents the two separate audio channels.\n",
    "\n",
    "This raw waveform can be further transformed and represented in a more meaningful way. For instance, Fourier Transformations can convert the time-domain data into frequency-domain data, showing the frequencies present in the sound over time. These transformed representations can give you a 2D tensor where one dimension represents time and the other represents frequency.\n",
    "\n",
    "### Video Data\n",
    "Video data is typically represented as a sequence of images or frames, where each frame is a two-dimensional grid of pixels. Each pixel can have one (for grayscale images) or three (for color images in RGB format) numerical values. So, a video can be seen as a three-dimensional structure (height x width x time) with an additional color dimension if it's a color video. Video data is a sequence of image frames. This data type is used in deep learning for action recognition, video classification, etc.\n",
    "\n",
    "When we talk about video data in the context of data representation or machine learning, we usually refer to the sequence of frames or images that constitute the visual component. The audio track associated with a video is usually considered separately and is handled as audio data.\n",
    "\n",
    "## Preprocessing\n",
    "Each type of data requires specific types of preprocessing to be effectively used in a deep learning model. For example, categorical data might be one-hot encoded, text data may be transformed into word embeddings, and image data might be normalized to fall within a specific range. When dealing with preprocessing, you have to be carefull about loss of information.\n",
    "\n",
    "### Loss of Information\n",
    "Loss of information generally refers to the reduction in the quality, quantity, completeness, or relevance of information. When manipuling data, it's crucial to manage loss of information carefully, as it can impact the performance of machine learning algorithms. Information should only be discarded if it is reasonably certain that it is not useful, or if the computational benefits of doing so outweigh the potential impact on algorithm performance.\n",
    "\n",
    "### Numerical Encoding\n",
    "Numerical encoding is a method of converting categorical data into numerical form. There are several types of numerical encoding, two of the most common being ordinal encoding and one-hot encoding.\n",
    "\n",
    "#### Ordinal Encoding\n",
    "This type of encoding is best suited for ordinal data, which is categorical data that has an inherent order. Each unique category value is assigned an integer value.\n",
    "\n",
    "Example<br>If you have a feature 'Size' with categories 'Small', 'Medium' and 'Large', these could be encoded as '1', '2', and '3' respectively.\n",
    "\n",
    "#### One-Hot Encoding\n",
    "This is used for nominal data, which is categorical data that does not have an inherent order. In this method, each category value is converted into a new vector to a binary class matrix. Each unique category in the original data corresponds to one (and only one) dimension in the transformed space, which takes the value of 1. All other dimensions in the one-hot vector are set to 0.<br>This is used for multi-class classification problems where the output layer uses a softmax activation function.\n",
    "\n",
    "Example<br>If you have a feature 'Color' with categories 'Red', 'Blue', and 'Green', one-hot encoding would create three new features 'Is_Red', 'Is_Blue', and 'Is_Green'. If an instance was 'Red', it would be encoded as 'Is_Red' = 1, 'Is_Blue' = 0, 'Is_Green' = 0.\n",
    "\n",
    "### Scaling\n",
    "Scaling is a technique to standardize the range of features of input data. When dealing with real-world data, we often find that different features are measured in different units, or that their scales do not match. This can cause problems in machine learning algorithms, especially those that rely on the distance between instances, like k-nearest neighbors, or those that use gradient descent to converge to a solution, like linear regression.<br>\n",
    "Machine learning algorithms perform better when numerical input variables are scaled to have similar ranges. This could mean normalizing the data to have a mean of 0 and a standard deviation of 1, or rescaling data to the range [0, 1].\n",
    "\n",
    "#### Normalization (Min-Max scaling) (Normalization layers)\n",
    "This process scales all numeric features to be between 0 and 1.<br>\n",
    "Normalization = (X - X.min) / (X.max - X.min)\n",
    "\n",
    "Example<br>\n",
    "Normalization([1, 2, 3, 4, 5]) = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "A type of layer that processes data and outputs it in a normalized form is called Normalization layers.\n",
    "\n",
    "#### Standardization\n",
    "This method scales the features such that they have properties of a standard normal distribution. Œº and œÉ are computed from the data, where Œº is the mean (average) and œÉ is the standard deviation from the mean. After standardization, the mean (Œº) will be 0 and the standard deviation (œÉ) will be 1.<br>\n",
    "Standardization = (X - Œº) / œÉ\n",
    "\n",
    "Example<br>\n",
    "Œº = mean([1, 2, 3, 4, 5]) = 3<br>\n",
    "œÉ = standard_deviation([1, 2, 3, 4, 5]) = 1.44<br>\n",
    "Standardization([1, 2, 3, 4, 5]) = [-1.41, -0.707, 0, 0.707, 1.41]\n",
    "\n",
    "### Embedding\n",
    "Embedding is a learned representation for text where words that have the same meaning have a similar representation. It is this approach to representing words and documents that may be considered one of the key breakthroughs of deep learning on challenging natural language processing problems.\n",
    "\n",
    "This is usually used in Natural Language Processing tasks to transform text data into a format that can be understood by the model, such as Word2Vec, GloVe, FastText, etc. They are a form of dimensionality reduction that can capture semantic relationships between words.\n",
    "\n",
    "\n",
    "The embedding layer can be understood as a lookup table that maps from integer indices (specific words) to dense vectors (their embeddings). It takes as input integers, it looks up these integers in an internal dictionary, and it returns the associated vectors. It's effectively a way of doing one-hot encoding in a much more efficient way.\n",
    "#### Word2Vec\n",
    "#### GloVe\n",
    "#### FastText\n",
    "#### Embedding Layer in Neural Networks\n",
    "#### Semantic Relationships in Embeddings\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "### Removing Duplicate Entries\n",
    "Duplicate entries may occur due to various reasons such as data entry errors or merging data from different sources. These duplicates can distort analysis and lead to incorrect conclusions.\n",
    "\n",
    "### Data Validation\n",
    "Checking the data against predefined rules and constraints like a certain field being non-null, unique, within a certain range, readable image...\n",
    "\n",
    "### Correcting Inconsistencies\n",
    "These could be due to various reasons such as different units of measurement, different data entry conventions, typos, etc. For example, in a column representing gender, entries could be \"M\", \"Male\", \"m\", all indicating the same thing. Identifying and correcting these inconsistencies is important.\n",
    "\n",
    "### Noise Reduction\n",
    "Noise is random variation in the data that can distort the pattern we want to understand. Noise reduction techniques eliminate or reduce the noise present in the dataset in order to smooth values. \n",
    "\n",
    "While it is crucial to reduce noise to improve model performance, it's also important not to overclean the data, which can result in loss of important information and overfitting the models to the training data. It's always a balance to find the right amount of cleaning required for a given dataset.\n",
    "\n",
    "#### Filtering\n",
    "This method is used primarily for time-series data or image data. Filters like the Kalman filter, moving averages, or various image filters can help reduce the noise.\n",
    "\n",
    "#### Binning\n",
    "Binning methods smooth a sorted data value by consulting its \"neighborhood\", that is, the values around it. The sorted values are divided into 'bins' or intervals and then multiple adjacent bins are combined based on some criteria (mean, median, boundaries...).\n",
    "\n",
    "#### Regression\n",
    "Regression models can be used to smooth the data. These models can capture the data trend and filter out the noise.\n",
    "\n",
    "#### Robust Methods\n",
    "Robust statistical methods are used when the noise follows a non-Gaussian distribution. These methods provide reliable estimates of the central tendency and variability despite the presence of noise.\n",
    "\n",
    "#### Image denoising\n",
    "In the case of image data, noise reduction can be done using techniques like Median Filtering, Gaussian Blurring, or more sophisticated techniques like Non-local Means Denoising.\n",
    "\n",
    "#### Outlier Detection and Handling\n",
    "Outliers are data points in a dataset that are significantly different from other values. There are multiple ways to detect outliers. The most classic is to sort values to check maximums and minumums. Another is to plot values. Some statistical methods exists to detect them (Z-score method, QR method).\n",
    "\n",
    "Handling outliers is a substantial part of data preprocessing as they can significantly affect the results of your data analysis or machine learning model:\n",
    "+ Deletion<br>Outliers are removed from the dataset. This is usually not recommended as it can result in loss of information.\n",
    "+ Imputation<br>Outliers are replaced with other values.\n",
    "+ Capping<br>Outliers are set to a specified maximum or minimum value.\n",
    "+ Discretization<br>Continuous values are converted into categorical counterparts.\n",
    "+ Transformation<br>Applying a mathematical function to transform the data, reducing the impact of the outlier (e.g., square root, log transformations).\n",
    "+ Binning<br>Converting continuous variables into categorical counterparts.\n",
    "\n",
    "### Handling Missing Values\n",
    "Many datasets have missing values, and different machine learning algorithms handle these in different ways. Some options for dealing with missing values include imputing missing values with the mean, median, or mode of the column, or using a model to predict the missing values based on other columns.\n",
    "\n",
    "#### Imputation\n",
    "Imputation is a method to fill missing values with substitute values. The nature of the substituted value can vary\n",
    "+ Constant imputation<br>This involves replacing all missing data with a constant value. This method is not highly recommended as it can lead to bias in the model, but can still be used if the missing data is not significant.\n",
    "+ Mean/Median/Mode imputation<br>Missing values are replaced with the mean (for continuous features) or median (for continuous non-normal features) or mode (for categorical features). This method assumes that the data are missing completely at random (MCAR).\n",
    "+ Predictive imputation<br>A machine learning algorithm like linear regression, KNN, or even a simple model like a random forest can predict the missing values. This is a better method when the data are not missing at random.\n",
    "\n",
    "#### Deletion\n",
    "If the number of missing values is small, then the rows containing missing values can be removed. This is typically not recommended as it can result in loss of information. Deletion methods are used when the nature of the missing data is \"Missing Completely At Random\" (MCAR), meaning the fact that the data is missing is independent of both the observable variables and unobservable parameters of interest.\n",
    "\n",
    "---\n",
    "\n",
    "Example<br>\n",
    "Suppose you have a dataset for predicting house prices, and one of the features is the \"number of rooms\", but some of these values are missing.\n",
    "+ If you choose to do mean imputation, you would calculate the mean number of rooms from the houses where this data is not missing, and fill the missing values with this mean.\n",
    "+ In case of predictive imputation, you could train a model (say, a linear regression model) on the rest of the data to predict the \"number of rooms\" feature. Then, you could use this model to fill the missing values.\n",
    "+ If you choose deletion, you would simply remove all the houses from the dataset where the \"number of rooms\" is not provided.\n",
    "\n",
    "## Dimensionality Reduction\n",
    "Dimensionality reduction is a key data preprocessing technique, especially in contexts where datasets have a high number of features. The main idea of dimensionality reduction is to reduce the number of input variables in a dataset. By reducing the dimension of your feature space, you have fewer relationships between variables to consider and you are less likely to overfit your model.\n",
    "\n",
    "### Feature Extraction\n",
    "Feature extraction involves transforming raw data into a set of features (or a feature vector) that effectively represent the essential information and underlying patterns in the data. This can be especially important for data like images or text. A common practice in image processing tasks is to use CNNs for feature extraction.\n",
    "\n",
    "Example<br>\n",
    "Consider that we are working with a dataset of images of cats and dogs and we want to build a machine learning model that can classify an image as either a cat or a dog. Raw pixel data can be quite high dimensional (e.g., an image with a resolution of 100x100 pixels already has 10,000 features) and it may not be the most effective representation of the images for the task of distinguishing cats from dogs. Instead of using raw pixel data, we could use a feature extraction method to identify and measure more meaningful properties of the images. We could use edge detection techniques to extract the shape of the animals in the images. These extracted features can then be used to train a machine learning model.\n",
    "\n",
    "### Feature Selection\n",
    "If you have a large number of features, it can be beneficial to select a subset of the most informative features to use for learning. This can reduce the dimensionality of the problem, reduce overfitting, improve accuracy, and reduce training time.\n",
    "\n",
    "Example<br>\n",
    "Let's say we have a dataset of 28x28 pixel grayscale images of handwritten digits (like the MNIST dataset). These images have 784 features (one for each pixel). Instead of directly using these 784 features, we might use an autoencoder to compress these images into a lower-dimensional space. For example, we might design an autoencoder with a single hidden layer containing 50 nodes. After training the autoencoder, we can use the weights to transform each 784-dimensional image into a 50-dimensional feature vector. These feature vectors can then be used as input to another deep learning model, such as a CNN or an MLP.\n",
    "\n",
    "### Flatten Tensor\n",
    "Flattening a tensor (or any multi-dimensional data structure) is an operation that transforms the tensor into a 1-dimensional tensor (or \"vector\") by placing the row elements into a single row. You often flatten tensors when you're transitioning between two types of layers. Flattening a tensor removes all of its structure except for the order of the elements. If that structure contained important information, then flattening could hurt your model's performance. For instance, you wouldn't flatten an image before feeding it into a CNN, because the spatial relationships between pixels are crucial for the CNN's performance.\n",
    "\n",
    "+ Transitioning from Convolutional Layers to Fully Connected Layers<br>In CNNs you often transition from convolutional and pooling layers, which work in 2D (or 3D, if considering color channels), to fully connected layers (Dense layers), which work in 1D. Before you can feed the output of your last convolutional layer into your first fully connected layer, you have to flatten that output.\n",
    "+ Input to certain types of layers<br>Some types of layers or operations expect input in a certain shape. For example, a Dense layer expects a single vector for each instance in the batch. If your data isn't already in that shape because it came from an operation that works over multiple dimensions (like a convolutional layer, recurrent layer or even another dense layer), you'd need to flatten it.\n",
    "+ For Final Output<br>Depending on the problem at hand, sometimes the output of the network needs to be a flattened tensor. For example, in a binary classification problem, the final output of the network is typically a single probability value, which can be thought of as a flattened 1D tensor with just one element.\n",
    "\n",
    "Example<br>flatten([[[1, 2, 3], \n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]],\n",
    "             [[10, 11, 12],\n",
    "              [13, 14, 15],\n",
    "              [16, 17, 18]]]) = [1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53244f",
   "metadata": {},
   "source": [
    "# APIs\n",
    "\n",
    "## NumPy (Numerical Python)\n",
    "NumPy is a Python library used for scientific computing. It provides a high-performance multidimensional array object and tools for working with these arrays. This is used extensively in data analysis and machine learning models as it allows for efficient operations on large datasets.<br>\n",
    "NumPy operations and functions are implemented in C, making them much faster than using Python's built-in sequences, and much more memory-efficient than built-in lists.\n",
    "\n",
    "Many other scientific and data analysis libraries are built on top of NumPy and use its array data structure as the basic building block.\n",
    "\n",
    "## Pandas\n",
    "Pandas is a popular open-source data manipulation and analysis library for Python. It provides flexible and efficient data structures for data manipulation, cleaning, and analysis. Its key data structures are called \"Series\" and \"DataFrame\".\n",
    "+ Series<br>A Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.\n",
    "+ DataFrame<br>A DataFrame is a two-dimensional labeled data structure with columns of potentially different types, similar to a spreadsheet or SQL table, or a dictionary of Series objects. It's like a dictionary of Series objects. It is generally the most commonly used pandas object.\n",
    "\n",
    "## Keras\n",
    "Keras is an open-source neural network library written in Python developed and maintained by Fran√ßois Chollet, a Google engineer, and it is officially part of the TensorFlow project. It's designed to enable fast experimentation with deep neural networks and it focuses on being user-friendly, modular, and extensible. Keras was developed with the goal to make it accessible to as many people as possible, including nonexperts people who aren‚Äôt researchers or graduate students. One mainly goal of Keras is for deep learning to reach its full potential, deep learning has to radically democratized.\n",
    "\n",
    "Keras supports multiple input and output models, including multi-input and multi-output models, shared-layer models, and even models with shared layers. This allows for more flexibility when it comes to model design. It's capable of running on top of TensorFlow, Microsoft Cognitive Toolkit, Theano, and PlaidML.\n",
    "\n",
    "## Tensorflow\n",
    "TensorFlow is an open-source machine learning library developed by the Google Brain team for conducting machine learning and deep neural networks research. Since its release in 2015, it has become one of the most widely used libraries for implementing, training, and deploying machine learning models. TensorFlow is used by numerous companies and organizations for machine learning tasks such as object detection, image and speech recognition, and it's been used in various research to publish papers in top ML conferences. It's also used in many products within Google, like Google Search, Google Photos, and Google Translate, to improve performance and capabilities.\n",
    "\n",
    "## PyTorch\n",
    "PyTorch is an open-source machine learning library developed by Facebook's AI Research lab, which is used for applications such as computer vision and natural language processing. PyTorch is used for both research and production due to its flexibility, speed, and seamless transition between CPU and GPU. It provides two high-level features: tensor computation with strong GPU acceleration and deep neural networks built on a type-based autograd system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0befc9b",
   "metadata": {},
   "source": [
    "# Applications (Python Keras)\n",
    "\n",
    "First of all, a util.py file containing all needed function and import is defined. You can execute the cell then go to the next cell.\n",
    "\n",
    "---\n",
    "util.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a644cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "import pickle\n",
    "import cv2\n",
    "from keras.applications import VGG16, MobileNetV2\n",
    "from keras.optimizers import SGD\n",
    "from typing import Iterable\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from numpy import float16, float32, ndarray, resize, uint8\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers, models\n",
    "from keras.layers import GlobalAveragePooling2D, Activation, Add, AveragePooling2D, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Input, Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simple_resnet_block(input_tensor, filters, kernel_size):\n",
    "    \"\"\" kernel_size: When you pass in an integer n for kernel_size, Keras interprets it as an n x n kernel. So kernel_size=3 is the same as kernel_size=(3, 3); both indicate a 3x3 convolutional kernel.\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = Add()([x, input_tensor])  # This is the \"residual\" connection\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def reshaping_images(images, size):\n",
    "    \"\"\" cv2.resize is getting way better result on the learning process than np.resize.\n",
    "    cv2.resize properly handle the resizing of color images, maintaining the color channels, and apply antialiasing techniques.\n",
    "    np.resize fills the new array with repeated copies of the original array in a C-like order.\n",
    "    When resizing images, you'll want to use a method that is aware of the spatial structure of images and can perform interpolation, such as OpenCV's cv2.resize, SciPy's scipy.ndimage.zoom, or Skimage's skimage.transform.resize.\n",
    "    These methods are specifically designed to handle the resizing of image data and will typically provide much better results than simple array resizing like np.resize. \"\"\"\n",
    "    return np.array([cv2.resize(img, (size, size)) for img in images])\n",
    "    # return np.array([np.resize(img, (size, size, 3)) for img in images])\n",
    "\n",
    "def reverse_dict(d: dict):\n",
    "    return {tuple(v) if type(v) is Iterable else v: k for (k, v) in d.items()}\n",
    "\n",
    "def train_n_save(model, history_path_save, model_path_save, train_data, validation_data, steps_per_epoch=100, epochs=100,\n",
    "                 validation_steps=50):\n",
    "    if type(train_data) is tuple:\n",
    "        train_feature, train_label = train_data\n",
    "        history = model.fit(train_feature, train_label, steps_per_epoch=steps_per_epoch, epochs=epochs,\n",
    "                            validation_data=validation_data, validation_steps=validation_steps)\n",
    "    else:\n",
    "        history = model.fit(train_data, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=validation_data,\n",
    "                            validation_steps=validation_steps)\n",
    "    save_history(history, history_path_save)\n",
    "    model.save(model_path_save)\n",
    "    return history.history\n",
    "\n",
    "\n",
    "def save_history(history: dict, path):\n",
    "    assert path.suffix == \".plk\"  # .plk file\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(history, file)\n",
    "\n",
    "\n",
    "def get_history(path):\n",
    "    assert path.suffix == \".plk\"\n",
    "    with open(path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def list_to_sentence(data, indice, library) -> str:\n",
    "    num_word = reverse_dict(library.get_word_index())\n",
    "    return \" \".join([num_word[nums] for nums in data[indice]])\n",
    "\n",
    "\n",
    "def lists2d_to_pad_tensor(data):\n",
    "    \"\"\" pad the sequences with zeros to ensure uniform length \"\"\"\n",
    "    max_length = max([len(nums) for nums in data])\n",
    "    results = np.zeros((len(data), max_length), dtype=int)\n",
    "    for i, sequence in enumerate(data):\n",
    "        results[i, :len(sequence)] = sequence\n",
    "    return results\n",
    "    # return [nums + [0] * (max_length - len(nums)) for nums in data]\n",
    "\n",
    "\n",
    "def lists2d_to_onehot_tensor(data, dimension=None):\n",
    "    \"\"\" converting the data into a one-hot encoding representation \"\"\"\n",
    "    results = np.zeros((len(data), dimension))\n",
    "    for i, sequence in enumerate(data):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "\n",
    "def show_history_charts(history: dict):\n",
    "    if type(history) is not dict:\n",
    "        history = history.history\n",
    "    import matplotlib.pyplot as plt\n",
    "    epochs = range(1, len(history['loss']) + 1)\n",
    "    print(\"history keys:\", list(history))\n",
    "    plt.rcParams['figure.figsize'] = (6, 6)\n",
    "    plt.rcParams[\"keymap.zoom\"].append(\"a\")\n",
    "    plt.rcParams[\"keymap.back\"].append(\"¬≤\")\n",
    "    names = [word for word in history if (\"_\" not in word or (\"acc\" in word and \"val\" not in word)) and \"loss\" not in word]\n",
    "    names += [\"loss\"]\n",
    "    fig, axs = plt.subplots(len(names))\n",
    "    print(names)\n",
    "    for i, name in enumerate(names):\n",
    "        axs[i].set_title(name)\n",
    "    validation_datas_present = False\n",
    "    for k, v in history.items():\n",
    "        i = next(i for (i, name) in enumerate(names) if name in k)\n",
    "        if \"loss\" in k:\n",
    "            if 'val' in k:\n",
    "                axs[i].plot(epochs, v, color='blue', label='Validation loss')\n",
    "                last_5_average = statistics.mean(v[int(len(v) * 0.9):])\n",
    "                axs[i].axhline(y=last_5_average, color=\"blue\", linestyle=\"-.\",\n",
    "                               label=\"Average model loss {:.2f}\".format(last_5_average))\n",
    "            else:\n",
    "                axs[i].plot(epochs, v, color='blue', label='Training loss', linestyle='', marker='o')\n",
    "        else:\n",
    "            if 'val' in k:\n",
    "                validation_datas_present = True\n",
    "                axs[i].plot(epochs, v, color='green', label=\"Validation \" + names[i])\n",
    "                last_5_average = statistics.mean(v[int(len(v) * 0.9):])\n",
    "                axs[i].axhline(y=last_5_average, color=\"green\", linestyle=\"-.\",\n",
    "                               label=\"Average model val {:.2f}\".format(last_5_average))\n",
    "            else:\n",
    "                axs[i].plot(epochs, v, color='green', label='Training ' + names[i], linestyle='', marker='o')\n",
    "    for i, name in enumerate(names):\n",
    "        axs[i].legend()\n",
    "    plt.xlabel('Epochs'), plt.ylabel('Loss'), plt.tight_layout()\n",
    "    plt.gcf().canvas.manager.set_window_title(\"Statistics on training{} datas\".format(\n",
    "        \"/validation\" if validation_datas_present else \"\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def featurewise_normalization(data) -> np.array:\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    normalized_data = (data - mean) / std\n",
    "    return normalized_data, mean, std\n",
    "\n",
    "\n",
    "def interpretable_featurewise_normalization(normalized_data, std) -> np.array:\n",
    "    return normalized_data * std\n",
    "\n",
    "\n",
    "def reverse_featurewise_normalization(normalized_data, mean, std) -> np.array:\n",
    "    return interpretable_featurewise_normalization(normalized_data, std) + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c8d06",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## MNIST (Modified National Institute of Standards and Technology)\n",
    "MNIST is the most classic dataset in the field of machine learning. It consists of a collection of 70,000 grayscale images, each of which is 28x28 pixels. These images represent handwritten digits from 0 to 9. The dataset is split into a training set of 60,000 images and a test set of 10,000 images. This dataset is often used as the \"Hello, World!\" of machine learning because it's a relatively straightforward, small, and easy-to-use dataset that doesn't require any pre-processing.<br>In Keras, the MNIST dataset is loaded using the mnist.load_data() function.\n",
    "\n",
    "### A straightforward and highly accurate solution\n",
    "This solution uses\n",
    "+ Learning algorithm\n",
    "    + Classification problem\n",
    "+ Architecture model\n",
    "    + DNN\n",
    "    + MLP\n",
    "    + FNN\n",
    "+ Data preprocessing\n",
    "    + Image\n",
    "        + Flatten tensor\n",
    "        + Normalization\n",
    "        + One-hot encoding\n",
    "+ Layers & Activation functions\n",
    "    + 1 Dense & ReLU\n",
    "    + 1 Dense & softmax\n",
    "+ Regularization techniques\n",
    "    + -\n",
    "+ Optimizer & Loss function\n",
    "    + rmsprop & categorical_crossentropy\n",
    "+ Mectrics\n",
    "    + Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94525d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_images: ndarray[uint8, list[list[list[int]]]]\n",
    "y_train_labels: ndarray[uint8, int]\n",
    "x_test_images: ndarray[uint8, list[list[list[int]]]]\n",
    "y_test_labels: ndarray[uint8, int]\n",
    "    \n",
    "### Data initialisation ###\n",
    "training_set, test_set = mnist.load_data()\n",
    "x_train_images, y_train_labels = training_set\n",
    "x_test_images, y_test_labels = test_set\n",
    "\n",
    "random_mnist_test_index = np.random.choice(len(x_test_images))\n",
    "random_mnist_test_image = x_test_images[random_mnist_test_index]\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].imshow(random_mnist_test_image, cmap=\"gray\")\n",
    "axs[1].imshow(random_mnist_test_image)\n",
    "# MNIST image are gray. Without specifying cmap='gray' it will show the image with the viridis colormap: a colorful gradient from purple (for low values) to yellow (for high values).\n",
    "plt.show()\n",
    "y_test_labels[random_mnist_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94715ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_images shape (60000, 28, 28) y_train_labels shape (60000,)\n",
      "x_train_images_2d shape (60000, 784) y_train_labels_matrix shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_2d_tensor: ndarray[float32, list[list[float]]]\n",
    "x_test_2d_tensor: ndarray[float32, list[list[float]]]\n",
    "y_train_labels_matrix: ndarray[float32, list[list[float]]]\n",
    "y_test_labels_matrix: ndarray[float32, list[list[float]]]\n",
    "\n",
    "### Data preprocessing ###\n",
    "flatten_shape = reduce(mul, x_train_images.shape[1:], 1)    # 28 * 28 * 1\n",
    "x_train_2d_tensor = x_train_images.reshape((len(x_train_images), flatten_shape)).astype(float32) / 255\n",
    "x_test_2d_tensor = x_test_images.reshape((len(x_test_images), flatten_shape)).astype(float32) / 255\n",
    "y_train_labels_matrix = to_categorical(y_train_labels)\n",
    "y_test_labels_matrix = to_categorical(y_test_labels)\n",
    "print(\"x_train_images shape\", x_train_images.shape, \"y_train_labels shape\", y_train_labels.shape)\n",
    "print(\"x_train_images_2d shape\", x_train_2d_tensor.shape, \"y_train_labels_matrix shape\", y_train_labels_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c2b86",
   "metadata": {},
   "source": [
    "### .reshape\n",
    "x_train_images.reshape((60000, 28 * 28)) is reshaping the input images from a 28x28 matrix to a flat 784 (28*28) element vector with of a float type.<br>\n",
    "This is done because the input layer is a fully connected layer (Dense layer) which expects a 1-dimensional input vector for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44dbdb3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[238, 107, 237, 161,  44],\n",
       "        [206,  98, 168, 206,  40],\n",
       "        [238, 148,  33,  37,  74]],\n",
       "\n",
       "       [[ 86,  99,  14, 145, 118],\n",
       "        [123,  32, 231, 233, 208],\n",
       "        [234,  49, 194, 250, 153]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_nparray_3D = np.random.randint(0, 255, size=(2, 3, 5))\n",
    "random_nparray_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4c9be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[238, 107, 237, 161,  44, 206,  98, 168, 206,  40, 238, 148,  33,\n",
       "          37,  74],\n",
       "        [ 86,  99,  14, 145, 118, 123,  32, 231, 233, 208, 234,  49, 194,\n",
       "         250, 153]]),\n",
       " array([238, 107, 237, 161,  44, 206,  98, 168, 206,  40, 238, 148,  33,\n",
       "         37,  74,  86,  99,  14, 145, 118, 123,  32, 231, 233, 208, 234,\n",
       "         49, 194, 250, 153]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_nparray_3D.reshape(2, 15), random_nparray_3D.reshape(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eedc0b",
   "metadata": {},
   "source": [
    "### .astype(float32)\n",
    "Neural network operations typically work on floating point values, so we always need to convert integers to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f615e913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[238., 107., 237., 161.,  44.],\n",
       "        [206.,  98., 168., 206.,  40.],\n",
       "        [238., 148.,  33.,  37.,  74.]],\n",
       "\n",
       "       [[ 86.,  99.,  14., 145., 118.],\n",
       "        [123.,  32., 231., 233., 208.],\n",
       "        [234.,  49., 194., 250., 153.]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_nparray_3D = random_nparray_3D.astype(float32)\n",
    "random_nparray_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88acb2ba",
   "metadata": {},
   "source": [
    "###  / 255\n",
    "Neural networks usually perform better on normalized data. By dividing by 255 (the maximum possible pixel intensity), all pixel intensities will now range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa48a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.93333334, 0.41960785, 0.92941177, 0.6313726 , 0.17254902],\n",
       "        [0.80784315, 0.38431373, 0.65882355, 0.80784315, 0.15686275],\n",
       "        [0.93333334, 0.5803922 , 0.12941177, 0.14509805, 0.2901961 ]],\n",
       "\n",
       "       [[0.3372549 , 0.3882353 , 0.05490196, 0.5686275 , 0.4627451 ],\n",
       "        [0.48235294, 0.1254902 , 0.90588236, 0.9137255 , 0.8156863 ],\n",
       "        [0.91764706, 0.19215687, 0.7607843 , 0.98039216, 0.6       ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_nparray_3D = random_nparray_3D.astype(float32) / 255\n",
    "random_nparray_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271aec7",
   "metadata": {},
   "source": [
    "### to_categorical()\n",
    "This is the One-hot encoding function in Keras that converts a int class vector to a binary class matrix. It converts the class labels into a one-hot encoded format. This is used for multi-class classification problems where the output layer uses a softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2b0def",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 6, 7, 4, 1, 7, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_nparray_1D = np.random.randint(0, 9, size=(10))\n",
    "random_nparray_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5006d8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrice = to_categorical(random_nparray_1D)\n",
    "matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023b3b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "### Model architecture ###\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape=(flatten_shape,)))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f0b29",
   "metadata": {},
   "source": [
    "### models.Sequential()\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor. It's a linear stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81504e13",
   "metadata": {},
   "source": [
    "### layers.Dense()\n",
    "Dense layers are fully connected layers, meaning each neuron in the layer is connected to all neurons in the previous layer. Here a Dense layer with 512 units (neurons) is added to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc36ff",
   "metadata": {},
   "source": [
    "### model.add()\n",
    "The model is added with a Dense layer specifying input_shape=(28 * 28,) indicates the shape of the input data that the layer will receive. The input shape need only be specified for the first layer in the model; subsequent layers automatically infer the shape from the preceding layer.\n",
    "\n",
    "Another Dense layer is added but this time with 10 units and a \"softmax\" activation function. This is the output layer of the model. The 10 units correspond to the 10 classes/features (digits 0-9) in the MNIST dataset. The softmax activation function turns the output of the layer into a probability distribution, so that the output of each neuron is a value between 0 and 1, representing the model's probability that the input belongs to the class represented by that neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96d3f8",
   "metadata": {},
   "source": [
    "### model.summary()\n",
    "This will show the architecture of the model, including the types of layers and the shape and number of parameters in each layer.\n",
    "\n",
    "Layer (type), Output Shape, Param # are the headers of the table that summarize the architecture of your model.\n",
    "+ Layer (type)<br>Lists the layers in your model in the order they are added. There is two Dense layers in the model.\n",
    "+ Output Shape<br>This describes the shape of the output produced by the layer. In the first layer (None, 512) means that the layer outputs a 2D tensor where the first dimension is batch size (unspecified here, hence None) and the second dimension is 512 (number of neurons in the layer).<br>For a Dense layer, the number of parameters is (inputs * outputs) + outputs, because each input connects to each output with a weight, and each output has a bias. So for the first Dense layer, (784 inputs * 512 neurons) + 512 biases = 401920 parameters. For the second layer, it's (512 inputs * 10 outputs) + 10 biases = 5130 parameters.\n",
    "+ Param #<br>The number of parameters (weights and biases) in the layer. The first Dense layer has 401,920 parameters, while the second Dense layer has 5,130 parameters.\n",
    "+ Total params<br>This is the total number of trainable parameters in the model, which is the sum of all parameters in each layer.\n",
    "+ Trainable params<br>This is the total number of parameters that will be updated during training. Here, all parameters in the model are trainable.\n",
    "+ Non-trainable params<br>These are the parameters that won't be updated during training. Usually, these are pre-trained parameters in case of using pre-trained models for transfer learning. This model don't have any non-trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c10ff6d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.2927 - accuracy: 0.9158 - val_loss: 0.1463 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1206 - accuracy: 0.9648 - val_loss: 0.1025 - val_accuracy: 0.9706\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0791 - accuracy: 0.9770 - val_loss: 0.0957 - val_accuracy: 0.9702\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0563 - accuracy: 0.9835 - val_loss: 0.0808 - val_accuracy: 0.9758\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.0785 - val_accuracy: 0.9772\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0786 - val_accuracy: 0.9781\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0793 - val_accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.0767 - val_accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.0765 - val_accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "### Model Evaluation ###\n",
    "# model.compile(optimizer=RMSprop(learning_rate=0.01), loss=CategoricalCrossentropy(), metrics=[CategoricalAccuracy()])\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x=x_train_2d_tensor, y=y_train_labels_matrix, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cccece",
   "metadata": {},
   "source": [
    "### model.compile()\n",
    "This is used to configure the learning process before training the model. \n",
    "\n",
    "The difference between loss function and metrics is that loss functions are used by optimization algorithms to train a model, and the metrics are used to measure the performance of the model. The goal of the model training is to minimize the loss. The metrics are designed to be a better understandable measure of the model performance for humans and have no impact on it.\n",
    "\n",
    "### model.fit()\n",
    "This method trains the model for a given number of epochs.\n",
    "+ x<br>x is the input data injected on the input layer<br>x_train_2d_tensor, the images from the MNIST dataset that have been preprocessed and reshaped into a 2D tensor.\n",
    "+ y<br>y is the target labels that the model tries to predict. The goal of the model is to learn this mapping from x to y so that it can correctly classify new, unseen images.<br>This y has been transformed into a \"one-hot\" representation by the to_categorical function, where each label is represented by a 1D array of 10 elements, all of which are 0 except for the index that corresponds to the actual digit (which is set to 1).\n",
    "+ epochs<br>This correspond to the number of learning iterations that the model will perform over the entire provided training data.\n",
    "+ batch_size<br>This corresponds to the number of samples that serve as a threshold after which the model will update its weights.\n",
    "+ validation_split<br>This specifies the portion of the training data to be held back and used as validation data during training. The validation data will be used to monitor the model's performance on unseen data as it trains. The metrics associated with this validation part will be printed on the standard output. The value 0.2 means 20% of the training data will be used for this purpose.\n",
    "+ history<br>It is the history object output. Its History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if specified). This can be used to visualize the training process, for example to create loss and accuracy plots over time.\n",
    "+ 5ms/step<br>That indicates the average time taken to evaluate each batch during the corresponding epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2621b4e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[3.3198472e-11 3.4937545e-10 1.5355408e-07 6.4116793e-12 8.9262542e-08\n",
      " 3.4959327e-11 9.9999976e-01 4.5934892e-13 2.1263732e-10 3.8609668e-15]\n",
      "6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "predict_first_image = model.predict(x_test_2d_tensor)[random_mnist_test_index]\n",
    "print(predict_first_image)\n",
    "print(np.where(predict_first_image == max(predict_first_image))[0][0])\n",
    "print(np.where(predict_first_image == max(predict_first_image))[0][0] == y_test_labels[random_mnist_test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1dd129",
   "metadata": {},
   "source": [
    "### model.predict()\n",
    "This method is used when you want to generate predictions on your data. Given some input data, model.predict() will return the model's predictions. The input to this function is typically new data that the model hasn't seen before. The output depends on the type of model you're using. In a classification model, model.predict() might output the probabilities that each sample belongs to each of the potential classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c145c1e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.2927182912826538, 0.12058074027299881, 0.07905570417642593, 0.05626117065548897, 0.042572010308504105, 0.03155858442187309, 0.024110058322548866, 0.01801176741719246, 0.013409881852567196, 0.009738325141370296], 'accuracy': [0.9157500267028809, 0.9647708535194397, 0.9769999980926514, 0.9835208058357239, 0.9877291917800903, 0.9908333420753479, 0.9931458234786987, 0.9954166412353516, 0.9967708587646484, 0.9977499842643738], 'val_loss': [0.14628835022449493, 0.10249581187963486, 0.09571627527475357, 0.08077992498874664, 0.07852858304977417, 0.07665646076202393, 0.0786459892988205, 0.07928730547428131, 0.07673665136098862, 0.07649380713701248], 'val_accuracy': [0.9581666588783264, 0.9705833196640015, 0.9701666831970215, 0.9757500290870667, 0.9771666526794434, 0.9777500033378601, 0.9780833125114441, 0.9770833253860474, 0.9793333411216736, 0.9792500138282776]}\n",
      "history keys: ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
      "['accuracy', 'loss']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history)\n",
    "show_history_charts(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1942649f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9811\n",
      "Accuracy: 0.9811\tLoss: 0.0625\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {1:.4f}\\tLoss: {0:.4f}\".format(*model.evaluate(x=x_test_2d_tensor, y=y_test_labels_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387aa362",
   "metadata": {},
   "source": [
    "### model.evaluate()\n",
    "\n",
    "This methode is used to test the model's performance over an unseen dataset. The model makes predictions for the input data x, compares these predictions to the true labels y, and then calculates the loss function and any other metrics that were specified during the compile step.\n",
    "\n",
    "The function returns a list where the first element is the value of the loss function on the testing data, and the remaining elements are the values of other metrics. 0.9817 corresponding to 98.17% is the percentage of the test images that were correctly classified by the model.\n",
    "\n",
    "To assess the model at the end of an epoch, you can use can give a validation_data argument or a validation_split argument.\n",
    "+ validation_data use a part of the training data for the evaluation.\n",
    "+ validation_split use the test data for the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2165f",
   "metadata": {},
   "source": [
    "## CIFAR-10 (Canadian Institute For Advanced Research with 10 different classes)\n",
    "This dataset contains 60,000 color images, each 32x32 pixels, divided into 10 classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks). Each class contains 6,000 images, and the dataset is split into 50,000 training images and 10,000 testing images.\n",
    "\n",
    "### A straightforward and lower accurate solution\n",
    "This solution is the same as the MNIST given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7817c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, optimizer, loss, metrics, batch_size=64, epochs=100, early_stopping=None):\n",
    "    if early_stopping:\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    history = model.fit(x=train_images_preprocessed, y=train_labels_preprocessed, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=(test_images_preprocessed, test_labels_preprocessed),\n",
    "                        # validation_split=0.2,\n",
    "                        callbacks=[early_stopping] if early_stopping else [])\n",
    "\n",
    "    predict_first_image = model.predict(test_images_preprocessed)[random_cifar_test_index]\n",
    "    print(classification_mapping[np.where(predict_first_image == max(predict_first_image))[0][0]],\n",
    "          np.where(predict_first_image == max(predict_first_image))[0][0] == test_labels[random_cifar_test_index][0])\n",
    "\n",
    "    show_history_charts(history)\n",
    "    print(\"Accuracy: {1:.4f}\\tLoss: {0:.4f}\".format(*model.evaluate(x=test_images_preprocessed, y=test_labels_preprocessed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a611b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n",
      "train_images shape (50000, 32, 32, 3) train_labels shape (50000, 1)\n",
      "train_images_preprocessed shape (50000, 3072) train_labels_preprocessed shape (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "### Data initialisation ###\n",
    "classification_mapping = [\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "training_set, test_set = cifar10.load_data()\n",
    "train_images, train_labels = training_set\n",
    "test_images, test_labels = test_set\n",
    "\n",
    "random_cifar_test_index = np.random.choice(len(test_images))\n",
    "random_cifar_test_image = test_images[random_cifar_test_index]\n",
    "plt.rcParams['figure.figsize'] = (2, 2)\n",
    "plt.imshow(random_cifar_test_image)\n",
    "plt.show()\n",
    "print(classification_mapping[test_labels[random_cifar_test_index][0]].capitalize())\n",
    "\n",
    "### Data preprocessing ###\n",
    "flatten_shape = reduce(mul, train_images.shape[1:], 1)    # 32 * 32 * 3\n",
    "train_images_preprocessed = train_images.reshape((len(train_images), flatten_shape)).astype(float32) / 255\n",
    "test_images_preprocessed = test_images.reshape((len(test_images), flatten_shape)).astype(float32) / 255\n",
    "train_labels_preprocessed = to_categorical(train_labels)\n",
    "test_labels_preprocessed = to_categorical(test_labels)\n",
    "print(\"train_images shape\", train_images.shape, \"train_labels shape\", train_labels.shape)\n",
    "print(\"train_images_preprocessed shape\", train_images_preprocessed.shape, \"train_labels_preprocessed shape\", train_labels_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb55d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 512)               1573376   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578,506\n",
      "Trainable params: 1,578,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 2.0695 - accuracy: 0.2928 - val_loss: 1.8234 - val_accuracy: 0.3453\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 1.7426 - accuracy: 0.3752 - val_loss: 1.7534 - val_accuracy: 0.3626\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 1.6740 - accuracy: 0.4035 - val_loss: 1.6470 - val_accuracy: 0.4088\n",
      "Epoch 4/20\n",
      "683/782 [=========================>....] - ETA: 1s - loss: 1.6334 - accuracy: 0.4206"
     ]
    }
   ],
   "source": [
    "### Model architecture ###\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape=(flatten_shape,)))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "### Model Evaluation ###\n",
    "model_evaluation(model, optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061205d0",
   "metadata": {},
   "source": [
    "As you can see, the accurate highly underperform compared with the same model on the MNIST (40% vs 98%).\n",
    "\n",
    "The current model is a simple fully connected neural network with a single hidden layer. Such a model might be too simple to effectively learn and generalize from the CIFAR-10 dataset, which contains more complex and high-dimensional images compared to the MNIST dataset. More layers can potentially extract more complex and abstract features from the images. The CIFAR-10 images are color images, while MNIST images are grayscale, the model doesn't take advantage of these additional color channels; it just treats them as additional individual features, which could lead to information loss.\n",
    "\n",
    "Let's tunning a bit this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model architecture ###\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512 * 2, activation=\"relu\", input_shape=(flatten_shape,)))\n",
    "model.add(layers.Dense(256 * 2, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(128 * 1, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "### Model Evaluation ###\n",
    "model_evaluation(model, optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6284bc58",
   "metadata": {},
   "source": [
    "Some enhancement has beed done but still, the model exhibits clear signs of overfitting capped at ~0.50. Consequently, we need to explore an alternative approach.\n",
    "\n",
    "#### EarlyStopping()\n",
    "EarlyStopping is a callbacks function that take a metric and monitor at each of epoch end if this metric stop increasing. If the metric has been triggered at least 'patience' times in a row, the training phase stops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98878498",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network solutions\n",
    "\n",
    "The first solution uses\n",
    "+ Learning algorithm\n",
    "    + Classification problem\n",
    "+ Architecture model\n",
    "    + DNN\n",
    "    + MLP\n",
    "    + FNN\n",
    "    + CNN\n",
    "+ Data preprocessing\n",
    "    + Image\n",
    "        + Normalization\n",
    "        + One-hot encoding\n",
    "+ Layers & Activation functions\n",
    "    + 3 Conv2D & ReLU\n",
    "    + 3 Maxpooling2D\n",
    "    + 1 Flatten layer\n",
    "    + 1 Dense layers & ReLU\n",
    "    + 1 Dense layers & softmax\n",
    "+ Regularization techniques\n",
    "    + Dropout\n",
    "+ Optimizer & Loss function\n",
    "    + rmsprop & categorical_crossentropy\n",
    "+ Mectrics\n",
    "    + Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d33bdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Data initialisation ###\n",
    "classification_mapping = [\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "training_set, test_set = cifar10.load_data()\n",
    "train_images, train_labels = training_set\n",
    "test_images, test_labels = test_set\n",
    "\n",
    "random_cifar_test_index = np.random.choice(len(test_images))\n",
    "random_cifar_test_image = test_images[random_cifar_test_index]\n",
    "plt.rcParams['figure.figsize'] = (2, 2)\n",
    "plt.imshow(random_cifar_test_image)\n",
    "plt.show()\n",
    "print(classification_mapping[test_labels[random_cifar_test_index][0]])\n",
    "\n",
    "### Data preprocessing ###\n",
    "train_images_preprocessed = train_images.astype(float32) / 255\n",
    "test_images_preprocessed = test_images.astype(float32) / 255\n",
    "train_labels_preprocessed = to_categorical(train_labels)\n",
    "test_labels_preprocessed = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1a22d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Model architecture ###\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "### Model Evaluation ###\n",
    "model_evaluation(model, optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6602d32",
   "metadata": {},
   "source": [
    "#### layers.Conv2D()\n",
    "The the first layer is a 2D convolutional layer, which applies 32 filters to the input data (filter are not neurons).<br>Each filter is of size 3x3 that has been given. This filter size is often used in image recognition tasks because it's small enough to capture detailed features but big enough to maintain computational efficiency.\n",
    "\n",
    "The other Conv2D layers are using 64 filters. It's common practice to increase the number of filters as you go deeper into the network, and there are a couple of reasons for this\n",
    "+ Increased Complexity<br>Early layers in the network are usually responsible for learning simple, low-level features like edges and textures. A smaller number of filters (like 32) is often sufficient for this. Deeper layers, on the other hand, are tasked with learning more complex, high-level features like shapes or specific object parts. To effectively capture these more complex features, a larger number of filters (like 64) is generally used.\n",
    "+ Dimensionality Reduction<br>Another common technique used in CNNs is to gradually reduce the spatial dimensions of the feature maps while increasing the number of filters. This helps to maintain a roughly constant amount of computation and parameters through the network. After a pooling layer, the height and width of the feature maps are reduced, meaning we can afford to increase the number of filters without significantly increasing the computational complexity.\n",
    "\n",
    "#### layers.MaxPooling2D()\n",
    "A 2D max pooling layer with a default window/kernel size of 2x2. Why 2x2?\n",
    "+ It requires fewer computational resources than larger windows. This can make the network faster to train and less memory-intensive\n",
    "+ It provides a good balance between maintaining spatial information (i.e., the relative positions of pixels in the image) and achieving spatial invariance (the ability of the network to recognize features regardless of where they appear in the image).\n",
    "\n",
    "Many successful models in the literature have used 2x2 windows, so it's often a good starting point when designing a new network. However, the best choice of window size will always depend on the specific problem and dataset, and it can be beneficial to experiment with different sizes.\n",
    "\n",
    "---\n",
    "\n",
    "The CNN architecture has achieved a higher accuracy of 65.06% compared to the accuracy of 44% from the previous model. Let's try to tune it by doubling it's hyperparameters and adding a dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f0c06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Model architecture ###\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32*2, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64*2, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64*2, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(64*2, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "### Model Evaluation ###\n",
    "model_evaluation(model, optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], batch_size=64*2, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf8e74",
   "metadata": {},
   "source": [
    "Increasing the depth of the network by doubling the number of filters in the Conv2D layers and adding a Dropout layer significantly improved the model's accuracy from 0.65 to 0.76. This suggests that the model benefits from a more complex architecture and regularization techniques to reduce overfitting, enhancing its generalization performance on unseen data.\n",
    "\n",
    "This model clearly overfit from the 20th epoch, let's tune the model with some regularization techniques: Data Augmentation, Batch Normalization and L2 regularization.\n",
    "\n",
    "This other solution uses\n",
    "+ Layers & Activation functions\n",
    "    + 3 Conv2D & ReLU\n",
    "    + 3 Maxpooling2D\n",
    "    + 1 Flatten layer\n",
    "    + 1 Dense layers & ReLU\n",
    "    + 1 Dense layers & softmax\n",
    "    + 2 ResNet (2)\n",
    "+ Regularization techniques\n",
    "    + Dropout\n",
    "    + Data augmentation (1)\n",
    "    + Batch normalization (1)\n",
    "    + L2 regularizer (1)\n",
    "    + ResNet (2)\n",
    "+ Optimizer & Loss function\n",
    "    + rmsprop & categorical_crossentropy (1)\n",
    "+ Mectrics\n",
    "    + Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8fe3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Data initialisation ###\n",
    "classification_mapping = [\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "training_set, test_set = cifar10.load_data()\n",
    "train_images, train_labels = training_set\n",
    "test_images, test_labels = test_set\n",
    "\n",
    "random_cifar_test_index = np.random.choice(len(test_images))\n",
    "random_cifar_test_image = test_images[random_cifar_test_index]\n",
    "plt.rcParams['figure.figsize'] = (2, 2)\n",
    "plt.imshow(random_cifar_test_image)\n",
    "plt.show()\n",
    "print(classification_mapping[test_labels[random_cifar_test_index][0]])\n",
    "\n",
    "### Data preprocessing ###\n",
    "train_images_preprocessed = train_images.astype(float32) / 255\n",
    "test_images_preprocessed = test_images.astype(float32) / 255\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "datagen.fit(train_images_preprocessed)\n",
    "train_labels_preprocessed = to_categorical(train_labels)\n",
    "test_labels_preprocessed = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be7a41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Model architecture ###\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32 * 2, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64 * 2, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64 * 2, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(64 * 2, activation='relu', kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "### Model Evaluation ###\n",
    "model_evaluation(model, optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], batch_size=128, epochs=10=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b54bd2",
   "metadata": {},
   "source": [
    "This model do not outperform the previous. It's slitly less good with an accuracy of 0.73.\n",
    "It's important to remember that not all regularization techniques or data augmentation will always lead to an increase in performance. Their effect is highly dependent on the data, the model, and how they are tuned. Regularization techniques are not magic tools.\n",
    "\n",
    "The dataset CIFAR-10 is quite complex, and achieving high accuracy usually requires deeper architectures or advanced techniques. Let's add a ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e35b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Model architecture ###\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "x = Conv2D(32 * 2, (3, 3), activation='relu', padding='same')(input_tensor)\n",
    "x = MaxPooling2D()(x)\n",
    "x = simple_resnet_block(x, 32 * 2, 3)\n",
    "x = Conv2D(64 * 2, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = simple_resnet_block(x, 64 * 2, 3)\n",
    "x = Conv2D(64 * 4, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64 * 4, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "model.summary()\n",
    "\n",
    "### Model Evaluation ###\n",
    "model_evaluation(model, optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], batch_size=64*2, early_stopping=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd739b",
   "metadata": {},
   "source": [
    "With some resnet_block the model accuracy increased by 2% (78%). We need to find something else. When you are out of idea, a fastforward solution is to use transfer learning by using a pre-trained models which are trained on large datasets like ImageNet. VGG16 will be used, we will replace some of the initial layers with VGG16 model. Let's use the VGG16 as a feature extractor and not include the fully connected layers at the top of the network. This may not be the optimal solution as it involves resampling of the original images, which can lead to loss of information or introduction of resampling artifacts.\n",
    "\n",
    "Resized images may still consume substantial memory so if you are limited by RAM, consider using MobileNetV2 instead of VGG16, as it has been trained on smaller images it allows to reduce the reshape on smaller dimensions.<br>Additionally, you may opt to use data type float16 instead of float32. This can considerably reduce the RAM allocated by the image tensor, although it may entail some loss of information. The effectiveness of using float16 depends on the dataset and whether the transformed values can still be meaningfully represented in this format. In many cases, float16 provides a practical trade-off between memory efficiency and precision.\n",
    "+ float64 range is approximately ¬±2.2e-308 to ¬±1.8e+308\n",
    "+ float32 range is approximately ¬±3.4e-38 to ¬±3.4e+38.\n",
    "+ float16 range is approximately ¬±6.1e-5 to ¬±6.5e+4.\n",
    "+ float8 doesnt exist.\n",
    "\n",
    "This solution use:\n",
    "+ Layers & Activation functions\n",
    "    + Transfert learning\n",
    "        + MobileNetV2\n",
    "    + 1 GlobalAveragePooling2D\n",
    "    + 1 Flatten layer\n",
    "    + 2 Dropout layers\n",
    "    + 5 Dense layers & ReLU\n",
    "+ Regularization techniques\n",
    "    + mobilenet_model\n",
    "    + Dropout\n",
    "    + Global average pooling\n",
    "    + Momentum\n",
    "    + LR\n",
    "+ Optimizer & Loss function\n",
    "    + SGD & categorical_crossentropy\n",
    "+ Mectrics\n",
    "    + Accuracy\n",
    "    \n",
    "#### VGG16\n",
    "VGG16 is a convolutional neural network model that achieved a top-5 error rate of 7.4% on the ImageNet Large Scale Visual Recognition Challenge 2014, a significant improvement over the models of the previous year. The \"16\" in VGG16 refers to the number of layers with weights, which are 13 convolutional layers and 3 fully-connected layers. It's noteworthy for its uniform architecture. That is, it always uses 3x3 kernels in the convolutional layers and 2x2 pooling kernels in the max-pooling layers, and it uses these small, consistent filter sizes with a deep stack of layers instead of few layers with large filters, which was a common practice previously.\n",
    "\n",
    "It has a very simple and uniform architecture, which can be a good baseline to compare with other complex architectures. It is a larger model in terms of memory and computation, making it slower to train. It only considers relatively small images (224 x 224) so for larger images, an excessive amount of pooling layers might cause a loss of valuable information.\n",
    "\n",
    "#### MobileNetV2\n",
    "MobileNetV2 is a convolutional neural network that's been trained on the ImageNet dataset, a large database of images labeled with various categories. MobileNetV2 is notable for its efficient performance, making it suitable for mobile devices, embedded systems, or any application where computational resources are limited. MobileNetV2 is widely used due to its balance between efficiency and accuracy. They have a default input size of 224x224 but can also work with other input sizes like 128x128, 160x160, 192x192, or 224x224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994c58e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RESHAPE_SIZE = 160 # resizing each image to have a height and width of RESHAPE_SIZE pixels\n",
    "\n",
    "### Data preprocessing ###\n",
    "train_images_reshaped = reshaping_images(train_images, RESHAPE_SIZE)\n",
    "test_images_reshaped = reshaping_images(test_images, RESHAPE_SIZE)\n",
    "train_images_preprocessed = train_images_reshaped.astype(float16) / 255\n",
    "test_images_preprocessed = test_images_reshaped.astype(float16) / 255\n",
    "train_labels_preprocessed = to_categorical(train_labels)\n",
    "test_labels_preprocessed = to_categorical(test_labels)\n",
    "\n",
    "### Model architecture ###\n",
    "# mobilenet_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(RESHAPE_SIZE, RESHAPE_SIZE, 3))\n",
    "mobilenet_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(RESHAPE_SIZE, RESHAPE_SIZE, 3))\n",
    "mobilenet_model.trainable = False\n",
    "# Construct the head of the model that will be placed on top of the base model\n",
    "inputs = Input(shape=(RESHAPE_SIZE, RESHAPE_SIZE, 3))\n",
    "headModel = mobilenet_model(inputs, training=False)\n",
    "headModel = GlobalAveragePooling2D()(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512 * 2, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(256 * 2, activation=\"relu\")(headModel)\n",
    "headModel = Dense(128 * 2, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.2)(headModel)\n",
    "headModel = Dense(64 * 2, activation=\"relu\")(headModel)\n",
    "headModel = Dense(10, activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=inputs, outputs=headModel)\n",
    "model.summary()\n",
    "\n",
    "### Model Evaluation ###\n",
    "model_evaluation(model, optimizer=SGD(learning_rate=0.001, momentum=0.9), loss=\"categorical_crossentropy\",\n",
    "                 metrics=[\"accuracy\"], batch_size=64 * 2, early_stopping=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed6bc1",
   "metadata": {},
   "source": [
    "After 3h of training, this model has obtained an accuracy of 84% on the test set.\n",
    "Each epoch last ~300 seconds. The first ends with an accuracy of 0.72 and the last ends with an accuracy of 0.84.\n",
    "\n",
    "The architecture consists of a pretrained MobileNetV2 as the base model, followed by a custom \"head\" comprising several fully connected layers, dropout for regularization, and a final softmax layer for classification. An input layer is used to match the shape of the MobileNetV2.\n",
    "\n",
    "When loading the MobileNetV2 we do not include the top layers (fully connected layers) because we want to add our own classifier layers for the CIFAR-10 classes. We then freeze the layers of the MobileNetV2 model to retain the learned features. Resizing is made to match the MobileNetV2 shape and the CIFAR-10 shape.\n",
    "\n",
    "This model has already been pretrained on a large dataset, and it is possible that the validation data resembles the data on which MobileNetV2 was originally trained. This could make the model perform better on the validation set compared to the training set (accuracy: 0.4903, val_accuracy: 0.7203)\n",
    "\n",
    "The CIFAR-10 dataset contain very small image (32x32), image are aproximative so it can be a difficult to determine. Only a few models are pre-trained on such small images. Therefore, achieving an accuracy higher than 80% requires delving into meticulous model tuning and leveraging pre-trained models specifically trained on very small images. That why it's complicated to obtain an accuracy more than 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a324a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "99px",
    "width": "373px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "386px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
